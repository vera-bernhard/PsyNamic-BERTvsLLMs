{
    "Meta-Llama-3-8B-Instruct": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.21270490178053206,
                    [
                        0.12035793280073738,
                        0.3025771618435199
                    ]
                ],
                "accuracy": [
                    0.20408163265306123,
                    [
                        0.1326530612244898,
                        0.2857142857142857
                    ]
                ],
                "precision": [
                    0.6637850171124351,
                    [
                        0.09029519197508117,
                        0.8398830863608384
                    ]
                ],
                "recall": [
                    0.25510204081632654,
                    [
                        0.17346938775510204,
                        0.336734693877551
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.4933281004709576,
                    [
                        0.3782659758402854,
                        0.5987705988857684
                    ]
                ],
                "accuracy": [
                    0.3877551020408163,
                    [
                        0.29591836734693877,
                        0.47959183673469385
                    ]
                ],
                "precision": [
                    0.8107333842627961,
                    [
                        0.6752720714326108,
                        0.8750756942611556
                    ]
                ],
                "recall": [
                    0.42857142857142855,
                    [
                        0.32653061224489793,
                        0.5204081632653061
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.29174843014128726,
                    [
                        0.1923291061146291,
                        0.4149076066650454
                    ]
                ],
                "accuracy": [
                    0.2857142857142857,
                    [
                        0.20408163265306123,
                        0.37755102040816324
                    ]
                ],
                "precision": [
                    0.738095238095238,
                    [
                        0.44085407836489676,
                        0.8481342836629149
                    ]
                ],
                "recall": [
                    0.29591836734693877,
                    [
                        0.21428571428571427,
                        0.3979591836734694
                    ]
                ]
            }
        }
    },
    "Llama-2-13b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.12414189420060259,
                    [
                        0.06283781202946276,
                        0.21245329022889162
                    ]
                ],
                "accuracy": [
                    0.21428571428571427,
                    [
                        0.14285714285714285,
                        0.30612244897959184
                    ]
                ],
                "precision": [
                    0.08863545418167267,
                    [
                        0.04152669865190208,
                        0.16699914003617444
                    ]
                ],
                "recall": [
                    0.21428571428571427,
                    [
                        0.14285714285714285,
                        0.30612244897959184
                    ]
                ]
            }
        }
    },
    "gpt-4o-mini": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.45882858637960683,
                    [
                        0.34857338137523647,
                        0.5664167032941549
                    ]
                ],
                "accuracy": [
                    0.3877551020408163,
                    [
                        0.29591836734693877,
                        0.493530417760009
                    ]
                ],
                "precision": [
                    0.7680643166357451,
                    [
                        0.6232308721028503,
                        0.8318540710618738
                    ]
                ],
                "recall": [
                    0.4387755102040816,
                    [
                        0.3376721661413075,
                        0.5408163265306123
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.397628016723931,
                    [
                        0.2919332065701945,
                        0.5049938926841249
                    ]
                ],
                "accuracy": [
                    0.3673469387755102,
                    [
                        0.2755102040816326,
                        0.4626919456995522
                    ]
                ],
                "precision": [
                    0.7283348121857438,
                    [
                        0.5377557385592687,
                        0.824977817213842
                    ]
                ],
                "recall": [
                    0.37755102040816324,
                    [
                        0.2857142857142857,
                        0.47574072530877093
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.465910671401682,
                    [
                        0.35717706736247473,
                        0.5689226299576777
                    ]
                ],
                "accuracy": [
                    0.4387755102040816,
                    [
                        0.3469387755102041,
                        0.5355079186867109
                    ]
                ],
                "precision": [
                    0.7416180758017493,
                    [
                        0.5986748689528513,
                        0.8216735780538558
                    ]
                ],
                "recall": [
                    0.4387755102040816,
                    [
                        0.3469387755102041,
                        0.5355079186867109
                    ]
                ]
            }
        }
    },
    "tuned": {
        "instruction_8b": {
            "metrics": {
                "f1-weighted": [
                    0.7225077180857069,
                    [
                        0.6275950567577434,
                        0.8025510771086589
                    ]
                ],
                "accuracy": [
                    0.6836734693877551,
                    [
                        0.5891655832595398,
                        0.7653061224489796
                    ]
                ],
                "precision": [
                    0.7957401928000594,
                    [
                        0.6756427601873388,
                        0.8765799608265585
                    ]
                ],
                "recall": [
                    0.6836734693877551,
                    [
                        0.5891655832595398,
                        0.7653061224489796
                    ]
                ]
            }
        }
    },
    "Llama-2-70b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.14335288771378996,
                    [
                        0.07555267594689448,
                        0.2261657264267684
                    ]
                ],
                "accuracy": [
                    0.20408163265306123,
                    [
                        0.1326530612244898,
                        0.29591836734693877
                    ]
                ],
                "precision": [
                    0.11626822157434401,
                    [
                        0.055541647370173856,
                        0.19982943469547837
                    ]
                ],
                "recall": [
                    0.20408163265306123,
                    [
                        0.1326530612244898,
                        0.29591836734693877
                    ]
                ]
            }
        }
    },
    "Llama-3.1-8B-Instruct": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.4001996847584021,
                    [
                        0.2921205197935078,
                        0.5092476244357121
                    ]
                ],
                "accuracy": [
                    0.3877551020408163,
                    [
                        0.29591836734693877,
                        0.47959183673469385
                    ]
                ],
                "precision": [
                    0.7638193575302461,
                    [
                        0.5962689821801193,
                        0.8369609938224484
                    ]
                ],
                "recall": [
                    0.3877551020408163,
                    [
                        0.29591836734693877,
                        0.47959183673469385
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.33335681739862927,
                    [
                        0.21834113629377716,
                        0.44375166271236133
                    ]
                ],
                "accuracy": [
                    0.3469387755102041,
                    [
                        0.25510204081632654,
                        0.4387755102040816
                    ]
                ],
                "precision": [
                    0.7397206342624132,
                    [
                        0.5164079489214021,
                        0.8216345173677785
                    ]
                ],
                "recall": [
                    0.3469387755102041,
                    [
                        0.25510204081632654,
                        0.4387755102040816
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.17061895180607453,
                    [
                        0.09693877551020408,
                        0.27720006511898115
                    ]
                ],
                "accuracy": [
                    0.21428571428571427,
                    [
                        0.14285714285714285,
                        0.30612244897959184
                    ]
                ],
                "precision": [
                    0.7983673469387754,
                    [
                        0.06926167652722308,
                        0.8572264885275819
                    ]
                ],
                "recall": [
                    0.23469387755102042,
                    [
                        0.16199972236502191,
                        0.32653061224489793
                    ]
                ]
            }
        }
    },
    "gpt-4o-2024-08-06": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7031792151889004,
                    [
                        0.6130499207613259,
                        0.791478540671073
                    ]
                ],
                "accuracy": [
                    0.6530612244897959,
                    [
                        0.5612244897959183,
                        0.7448979591836735
                    ]
                ],
                "precision": [
                    0.7938359017076219,
                    [
                        0.6831488964550149,
                        0.8769737793330245
                    ]
                ],
                "recall": [
                    0.6530612244897959,
                    [
                        0.5612244897959183,
                        0.7448979591836735
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7394585364510177,
                    [
                        0.6426269575962236,
                        0.8136896462545872
                    ]
                ],
                "accuracy": [
                    0.7040816326530612,
                    [
                        0.6122448979591837,
                        0.7857142857142857
                    ]
                ],
                "precision": [
                    0.8298469387755102,
                    [
                        0.7243166366842312,
                        0.8905292692838032
                    ]
                ],
                "recall": [
                    0.7040816326530612,
                    [
                        0.6122448979591837,
                        0.7857142857142857
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.715391621129326,
                    [
                        0.6215830138933163,
                        0.8036645715596504
                    ]
                ],
                "accuracy": [
                    0.673469387755102,
                    [
                        0.5714285714285714,
                        0.7653061224489796
                    ]
                ],
                "precision": [
                    0.7827057424670054,
                    [
                        0.6679877381954042,
                        0.8721007720351196
                    ]
                ],
                "recall": [
                    0.673469387755102,
                    [
                        0.5714285714285714,
                        0.7653061224489796
                    ]
                ]
            }
        }
    },
    "MeLLaMA-70B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.36725551345475965,
                    [
                        0.2675557244740531,
                        0.4941399421206959
                    ]
                ],
                "accuracy": [
                    0.336734693877551,
                    [
                        0.25510204081632654,
                        0.4489795918367347
                    ]
                ],
                "precision": [
                    0.782408544432503,
                    [
                        0.5816406705688337,
                        0.8705882973860641
                    ]
                ],
                "recall": [
                    0.336734693877551,
                    [
                        0.25510204081632654,
                        0.4489795918367347
                    ]
                ]
            }
        }
    },
    "Med-LLaMA3-8B": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "accuracy": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "precision": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "recall": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "accuracy": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "precision": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "recall": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.1000197657755596,
                    [
                        0.05128660159716061,
                        0.1791201193821886
                    ]
                ],
                "accuracy": [
                    0.22448979591836735,
                    [
                        0.15306122448979592,
                        0.3163265306122449
                    ]
                ],
                "precision": [
                    0.7531887755102041,
                    [
                        0.054902839400497054,
                        0.8724309877179239
                    ]
                ],
                "recall": [
                    0.22448979591836735,
                    [
                        0.15306122448979592,
                        0.3163265306122449
                    ]
                ]
            }
        }
    },
    "MeLLaMA-13B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.54174210695326,
                    [
                        0.4275630792207025,
                        0.6394539602398305
                    ]
                ],
                "accuracy": [
                    0.47959183673469385,
                    [
                        0.3723201837789699,
                        0.5816326530612245
                    ]
                ],
                "precision": [
                    0.7272575696945446,
                    [
                        0.5921761909199976,
                        0.8239672409745489
                    ]
                ],
                "recall": [
                    0.47959183673469385,
                    [
                        0.3723201837789699,
                        0.5816326530612245
                    ]
                ]
            }
        }
    },
    "medgemma-27b-text-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6152603117749832,
                    [
                        0.5065048100206613,
                        0.7108211235286577
                    ]
                ],
                "accuracy": [
                    0.5612244897959183,
                    [
                        0.45918367346938777,
                        0.6632653061224489
                    ]
                ],
                "precision": [
                    0.8306841967556253,
                    [
                        0.7654452420458795,
                        0.8739992044680944
                    ]
                ],
                "recall": [
                    0.5612244897959183,
                    [
                        0.45918367346938777,
                        0.6632653061224489
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.42462260301917587,
                    [
                        0.31468061442519474,
                        0.5351467147032137
                    ]
                ],
                "accuracy": [
                    0.3877551020408163,
                    [
                        0.29591836734693877,
                        0.47959183673469385
                    ]
                ],
                "precision": [
                    0.7939134095196521,
                    [
                        0.595786406734249,
                        0.8696611009662911
                    ]
                ],
                "recall": [
                    0.3877551020408163,
                    [
                        0.29591836734693877,
                        0.47959183673469385
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.444332860334637,
                    [
                        0.3349606892539731,
                        0.5432524430939178
                    ]
                ],
                "accuracy": [
                    0.40816326530612246,
                    [
                        0.30612244897959184,
                        0.5
                    ]
                ],
                "precision": [
                    0.8226832691118406,
                    [
                        0.7545417305236876,
                        0.8682892548787996
                    ]
                ],
                "recall": [
                    0.40816326530612246,
                    [
                        0.30612244897959184,
                        0.5
                    ]
                ]
            }
        }
    },
    "gemma-3-27b-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.22745909174480602,
                    [
                        0.13699159525575,
                        0.34584918306130014
                    ]
                ],
                "accuracy": [
                    0.2755102040816326,
                    [
                        0.19387755102040816,
                        0.3673469387755102
                    ]
                ],
                "precision": [
                    0.7990962099125364,
                    [
                        0.7208273253739226,
                        0.8478764554147188
                    ]
                ],
                "recall": [
                    0.2755102040816326,
                    [
                        0.19387755102040816,
                        0.3673469387755102
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.3293272864701436,
                    [
                        0.21578490500299272,
                        0.44079125125919083
                    ]
                ],
                "accuracy": [
                    0.32653061224489793,
                    [
                        0.23469387755102042,
                        0.41836734693877553
                    ]
                ],
                "precision": [
                    0.7485827664399093,
                    [
                        0.4809130465352214,
                        0.8342403628117915
                    ]
                ],
                "recall": [
                    0.32653061224489793,
                    [
                        0.23469387755102042,
                        0.41836734693877553
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.24994434137291283,
                    [
                        0.14980681624828182,
                        0.3642079373444242
                    ]
                ],
                "accuracy": [
                    0.2653061224489796,
                    [
                        0.1836734693877551,
                        0.35714285714285715
                    ]
                ],
                "precision": [
                    0.8067807768268598,
                    [
                        0.7345472138680773,
                        0.8573744346041478
                    ]
                ],
                "recall": [
                    0.2755102040816326,
                    [
                        0.19387755102040816,
                        0.3673469387755102
                    ]
                ]
            }
        }
    }
}