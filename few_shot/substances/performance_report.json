{
    "Meta-Llama-3-8B-Instruct": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8021653501931431,
                    [
                        0.7224926073339907,
                        0.8524327018803696
                    ]
                ],
                "accuracy": [
                    0.6458333333333334,
                    [
                        0.5416666666666666,
                        0.7395833333333334
                    ]
                ],
                "precision": [
                    0.8197148676764056,
                    [
                        0.6870860076808398,
                        0.8821252219155913
                    ]
                ],
                "recall": [
                    0.8473282442748091,
                    [
                        0.7786259541984732,
                        0.900390290826493
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.831839116902972,
                    [
                        0.740186332043498,
                        0.8793081809051345
                    ]
                ],
                "accuracy": [
                    0.7291666666666666,
                    [
                        0.6354166666666666,
                        0.8125
                    ]
                ],
                "precision": [
                    0.8455866908091177,
                    [
                        0.7422114167056028,
                        0.8993565138258621
                    ]
                ],
                "recall": [
                    0.8549618320610687,
                    [
                        0.7820759061592291,
                        0.904
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7953054043853562,
                    [
                        0.719630765092116,
                        0.8506066740936115
                    ]
                ],
                "accuracy": [
                    0.6770833333333334,
                    [
                        0.5833333333333334,
                        0.7802669450968729
                    ]
                ],
                "precision": [
                    0.811486171006516,
                    [
                        0.7346616823080016,
                        0.9038162125923319
                    ]
                ],
                "recall": [
                    0.816793893129771,
                    [
                        0.746127145906429,
                        0.8755887829050739
                    ]
                ]
            }
        }
    },
    "Llama-2-13b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7077525491402556,
                    [
                        0.6233853529539197,
                        0.785315362558323
                    ]
                ],
                "accuracy": [
                    0.6041666666666666,
                    [
                        0.5104166666666666,
                        0.7083333333333334
                    ]
                ],
                "precision": [
                    0.7892281594571671,
                    [
                        0.7311177738420009,
                        0.8917926250377176
                    ]
                ],
                "recall": [
                    0.6870229007633588,
                    [
                        0.59245983687998,
                        0.769389406324184
                    ]
                ]
            }
        }
    },
    "gpt-4o-2024-08-06": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.9207121003595705,
                    [
                        0.8803996137796432,
                        0.9444227275248076
                    ]
                ],
                "accuracy": [
                    0.78125,
                    [
                        0.6875,
                        0.8541666666666666
                    ]
                ],
                "precision": [
                    0.9063891942668092,
                    [
                        0.8710490121060879,
                        0.9399597929687104
                    ]
                ],
                "recall": [
                    0.9541984732824428,
                    [
                        0.9118453991800304,
                        0.9774790283844437
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.9176845800321488,
                    [
                        0.8746135263721297,
                        0.9428631833069676
                    ]
                ],
                "accuracy": [
                    0.7708333333333334,
                    [
                        0.6770833333333334,
                        0.84375
                    ]
                ],
                "precision": [
                    0.9016876646245057,
                    [
                        0.8562526676296708,
                        0.9293199083141918
                    ]
                ],
                "recall": [
                    0.9389312977099237,
                    [
                        0.8865260920481959,
                        0.96875
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.9143039911553766,
                    [
                        0.8575323167864098,
                        0.942718523307159
                    ]
                ],
                "accuracy": [
                    0.7916666666666666,
                    [
                        0.6979166666666666,
                        0.8645833333333334
                    ]
                ],
                "precision": [
                    0.9023237969400273,
                    [
                        0.8584395028748091,
                        0.9424157131771197
                    ]
                ],
                "recall": [
                    0.9389312977099237,
                    [
                        0.8796992481203008,
                        0.969989448226223
                    ]
                ]
            }
        }
    },
    "tuned": {
        "instruction_8b": {
            "metrics": {
                "f1-weighted": [
                    0.8618077534883897,
                    [
                        0.796301995746421,
                        0.9088514423946004
                    ]
                ],
                "accuracy": [
                    0.78125,
                    [
                        0.6949202440331648,
                        0.8541666666666666
                    ]
                ],
                "precision": [
                    0.9010073368635597,
                    [
                        0.834967152257678,
                        0.9511026620117254
                    ]
                ],
                "recall": [
                    0.8625954198473282,
                    [
                        0.8,
                        0.9083333333333333
                    ]
                ]
            }
        }
    },
    "gpt-4o-mini": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8614182078135043,
                    [
                        0.7939240979644722,
                        0.9012553554375458
                    ]
                ],
                "accuracy": [
                    0.71875,
                    [
                        0.6145833333333334,
                        0.8020833333333334
                    ]
                ],
                "precision": [
                    0.8520900530778477,
                    [
                        0.7639241557648071,
                        0.9007883300805131
                    ]
                ],
                "recall": [
                    0.8854961832061069,
                    [
                        0.8257882362530716,
                        0.9283664904842691
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8820771653317206,
                    [
                        0.8188367059652749,
                        0.9166736659743956
                    ]
                ],
                "accuracy": [
                    0.7395833333333334,
                    [
                        0.6364326135435551,
                        0.8229166666666666
                    ]
                ],
                "precision": [
                    0.8490640167050858,
                    [
                        0.7637552710747589,
                        0.8958165440943974
                    ]
                ],
                "recall": [
                    0.9236641221374046,
                    [
                        0.8733351119793152,
                        0.957983193277311
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8916509168486846,
                    [
                        0.8378189804486522,
                        0.9250612776274715
                    ]
                ],
                "accuracy": [
                    0.75,
                    [
                        0.6458333333333334,
                        0.8326776372262035
                    ]
                ],
                "precision": [
                    0.8596353737007095,
                    [
                        0.7955381143951199,
                        0.8971796282074284
                    ]
                ],
                "recall": [
                    0.9312977099236641,
                    [
                        0.8736270004694451,
                        0.9659553401676292
                    ]
                ]
            }
        }
    },
    "Llama-2-70b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8223368561420697,
                    [
                        0.7503223023935404,
                        0.8764757280554527
                    ]
                ],
                "accuracy": [
                    0.71875,
                    [
                        0.625,
                        0.8020833333333334
                    ]
                ],
                "precision": [
                    0.841290732314686,
                    [
                        0.7472852286947888,
                        0.8923827389850775
                    ]
                ],
                "recall": [
                    0.8396946564885496,
                    [
                        0.7728369225353217,
                        0.8925619834710744
                    ]
                ]
            }
        }
    },
    "Med-LLaMA3-8B": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.18929590341804078,
                    [
                        0.1288111951962554,
                        0.27386635568122364
                    ]
                ],
                "accuracy": [
                    0.13541666666666666,
                    [
                        0.07291666666666667,
                        0.21875
                    ]
                ],
                "precision": [
                    0.260099030328038,
                    [
                        0.15745805845578098,
                        0.40266048160630713
                    ]
                ],
                "recall": [
                    0.17557251908396945,
                    [
                        0.11851851851851852,
                        0.25645940316365384
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.550386713359111,
                    [
                        0.4744492065118716,
                        0.638753099611556
                    ]
                ],
                "accuracy": [
                    0.4166666666666667,
                    [
                        0.3229166666666667,
                        0.5208333333333334
                    ]
                ],
                "precision": [
                    0.5767495108936435,
                    [
                        0.483712443030876,
                        0.6499042124143958
                    ]
                ],
                "recall": [
                    0.5648854961832062,
                    [
                        0.48484848484848486,
                        0.6591556421586252
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "accuracy": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "precision": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "recall": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ]
            }
        }
    },
    "medgemma-27b-text-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.9190048268797169,
                    [
                        0.8790272823877482,
                        0.9476317283592851
                    ]
                ],
                "accuracy": [
                    0.8020833333333334,
                    [
                        0.71875,
                        0.875
                    ]
                ],
                "precision": [
                    0.9051089986876201,
                    [
                        0.85983476242258,
                        0.9469051992637523
                    ]
                ],
                "recall": [
                    0.9465648854961832,
                    [
                        0.9015151515151515,
                        0.9765625
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.9036046873531807,
                    [
                        0.8627358516126699,
                        0.9345083938083729
                    ]
                ],
                "accuracy": [
                    0.75,
                    [
                        0.6666666666666666,
                        0.8333333333333334
                    ]
                ],
                "precision": [
                    0.9023008732529814,
                    [
                        0.8579303677931972,
                        0.9404440972514322
                    ]
                ],
                "recall": [
                    0.9236641221374046,
                    [
                        0.8702415221655103,
                        0.958503926181132
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8717796558359553,
                    [
                        0.8133598586141659,
                        0.9132517936014517
                    ]
                ],
                "accuracy": [
                    0.7604166666666666,
                    [
                        0.6770833333333334,
                        0.84375
                    ]
                ],
                "precision": [
                    0.9033006986802877,
                    [
                        0.8535706643993763,
                        0.9560447023222555
                    ]
                ],
                "recall": [
                    0.8625954198473282,
                    [
                        0.7921856653684004,
                        0.9098360655737705
                    ]
                ]
            }
        }
    },
    "Llama-3.1-8B-Instruct": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8467555657591818,
                    [
                        0.7613561790595126,
                        0.8882452817839854
                    ]
                ],
                "accuracy": [
                    0.6979166666666666,
                    [
                        0.6041666666666666,
                        0.78125
                    ]
                ],
                "precision": [
                    0.8196224442528027,
                    [
                        0.7073050075893396,
                        0.8659755110766593
                    ]
                ],
                "recall": [
                    0.9007633587786259,
                    [
                        0.8274424507902953,
                        0.9416666666666667
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8360221420910371,
                    [
                        0.7589739525052234,
                        0.893752785649942
                    ]
                ],
                "accuracy": [
                    0.7395833333333334,
                    [
                        0.65625,
                        0.8229166666666666
                    ]
                ],
                "precision": [
                    0.8983762690873166,
                    [
                        0.7964559774858557,
                        0.9533172248796805
                    ]
                ],
                "recall": [
                    0.8320610687022901,
                    [
                        0.756128085236224,
                        0.8888888888888888
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8402147531412035,
                    [
                        0.7581714187311923,
                        0.8895866063136562
                    ]
                ],
                "accuracy": [
                    0.6875,
                    [
                        0.5833333333333334,
                        0.78125
                    ]
                ],
                "precision": [
                    0.8641658181668711,
                    [
                        0.7433979708671052,
                        0.914404093525677
                    ]
                ],
                "recall": [
                    0.8549618320610687,
                    [
                        0.7801851942425954,
                        0.9034543149355443
                    ]
                ]
            }
        }
    },
    "MeLLaMA-70B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8364035369069284,
                    [
                        0.7657062289390455,
                        0.8799298667571404
                    ]
                ],
                "accuracy": [
                    0.6770833333333334,
                    [
                        0.5833333333333334,
                        0.7604166666666666
                    ]
                ],
                "precision": [
                    0.8384910650298204,
                    [
                        0.720879705171639,
                        0.887497870793731
                    ]
                ],
                "recall": [
                    0.8778625954198473,
                    [
                        0.8229852331042486,
                        0.921875
                    ]
                ]
            }
        }
    },
    "MeLLaMA-13B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6891375884583804,
                    [
                        0.6043412152474653,
                        0.7676456328426728
                    ]
                ],
                "accuracy": [
                    0.625,
                    [
                        0.53125,
                        0.71875
                    ]
                ],
                "precision": [
                    0.7899551678177633,
                    [
                        0.7323375098045793,
                        0.8922661769520169
                    ]
                ],
                "recall": [
                    0.6641221374045801,
                    [
                        0.5700722798811779,
                        0.7478991596638656
                    ]
                ]
            }
        }
    },
    "gemma-3-27b-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.9045306956423799,
                    [
                        0.8613285236338514,
                        0.930966136230175
                    ]
                ],
                "accuracy": [
                    0.7604166666666666,
                    [
                        0.6770833333333334,
                        0.84375
                    ]
                ],
                "precision": [
                    0.8694436650477713,
                    [
                        0.8200275187169372,
                        0.9108855127188401
                    ]
                ],
                "recall": [
                    0.9618320610687023,
                    [
                        0.9188517879758251,
                        0.9848484848484849
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8516391827814302,
                    [
                        0.7841958754458713,
                        0.8919243822615115
                    ]
                ],
                "accuracy": [
                    0.71875,
                    [
                        0.6145833333333334,
                        0.7989593397650504
                    ]
                ],
                "precision": [
                    0.8360347053631989,
                    [
                        0.7524848138202233,
                        0.8799381650426294
                    ]
                ],
                "recall": [
                    0.8702290076335878,
                    [
                        0.8010492423463822,
                        0.9237198677048909
                    ]
                ]
            }
        }
    }
}