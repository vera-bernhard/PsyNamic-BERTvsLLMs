{
    "MeLLaMA-13B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.39880358818411915,
                    [
                        0.34980287756225864,
                        0.44312553957109463
                    ]
                ],
                "accuracy": [
                    0.2831858407079646,
                    [
                        0.2407079646017699,
                        0.32035398230088497
                    ]
                ],
                "precision": [
                    0.6798362201713126,
                    [
                        0.6151088030406717,
                        0.7370886954495839
                    ]
                ],
                "recall": [
                    0.2831858407079646,
                    [
                        0.2407079646017699,
                        0.32035398230088497
                    ]
                ]
            }
        }
    },
    "tuned": {
        "instruction_8b": {
            "metrics": {
                "f1-weighted": [
                    0.8523970068657224,
                    [
                        0.8224241803587993,
                        0.8813494122797488
                    ]
                ],
                "accuracy": [
                    0.8513274336283185,
                    [
                        0.8212389380530973,
                        0.8808107782545997
                    ]
                ],
                "precision": [
                    0.8603731342620049,
                    [
                        0.830399429091884,
                        0.8859339395532013
                    ]
                ],
                "recall": [
                    0.8513274336283185,
                    [
                        0.8212389380530973,
                        0.8808107782545997
                    ]
                ]
            }
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6648741035897594,
                    [
                        0.6227192939855579,
                        0.7079481380181416
                    ]
                ],
                "accuracy": [
                    0.6814159292035398,
                    [
                        0.6424778761061947,
                        0.7220087880773418
                    ]
                ],
                "precision": [
                    0.6816630040981173,
                    [
                        0.6406102973348663,
                        0.7196475705063423
                    ]
                ],
                "recall": [
                    0.6814159292035398,
                    [
                        0.6424778761061947,
                        0.7220087880773418
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.4157955413704725,
                    [
                        0.3677105073047218,
                        0.4685404248416356
                    ]
                ],
                "accuracy": [
                    0.4902654867256637,
                    [
                        0.449013759074105,
                        0.5345132743362832
                    ]
                ],
                "precision": [
                    0.6682088800192785,
                    [
                        0.5913471774713593,
                        0.7148281925576353
                    ]
                ],
                "recall": [
                    0.49380530973451325,
                    [
                        0.45309734513274336,
                        0.5380530973451327
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.592224319436709,
                    [
                        0.5439168170147697,
                        0.6443774901976433
                    ]
                ],
                "accuracy": [
                    0.6548672566371682,
                    [
                        0.6176991150442478,
                        0.6973451327433628
                    ]
                ],
                "precision": [
                    0.7035183628318584,
                    [
                        0.6554070304075992,
                        0.7496794263234439
                    ]
                ],
                "recall": [
                    0.6548672566371682,
                    [
                        0.6176991150442478,
                        0.6973451327433628
                    ]
                ]
            }
        }
    },
    "gpt-4o-2024-08-06": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7909420345220363,
                    [
                        0.7575313721172611,
                        0.8234177917054343
                    ]
                ],
                "accuracy": [
                    0.7893805309734513,
                    [
                        0.7553426140514533,
                        0.822684461745975
                    ]
                ],
                "precision": [
                    0.8000052633636137,
                    [
                        0.7673561371747315,
                        0.8318311146670102
                    ]
                ],
                "recall": [
                    0.7893805309734513,
                    [
                        0.7553426140514533,
                        0.822684461745975
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.7022183362720832,
                    [
                        0.6613586442731885,
                        0.7381330590550678
                    ]
                ],
                "accuracy": [
                    0.7044247787610619,
                    [
                        0.6637168141592921,
                        0.7398230088495575
                    ]
                ],
                "precision": [
                    0.7662571668951764,
                    [
                        0.7305479596454906,
                        0.7955206047378609
                    ]
                ],
                "recall": [
                    0.7044247787610619,
                    [
                        0.6637168141592921,
                        0.7398230088495575
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7008163648556229,
                    [
                        0.6606140967124794,
                        0.7365070657641092
                    ]
                ],
                "accuracy": [
                    0.7026548672566372,
                    [
                        0.6619469026548672,
                        0.7370579177672928
                    ]
                ],
                "precision": [
                    0.7614774243777465,
                    [
                        0.7249759015253449,
                        0.791773980332328
                    ]
                ],
                "recall": [
                    0.7026548672566372,
                    [
                        0.6619469026548672,
                        0.7370579177672928
                    ]
                ]
            }
        }
    },
    "Llama-3.1-8B-Instruct": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5838016711131337,
                    [
                        0.5398261289203811,
                        0.6239701618429481
                    ]
                ],
                "accuracy": [
                    0.5752212389380531,
                    [
                        0.5345132743362832,
                        0.6176991150442478
                    ]
                ],
                "precision": [
                    0.6736136176797718,
                    [
                        0.6269808578750887,
                        0.7111331908369126
                    ]
                ],
                "recall": [
                    0.5752212389380531,
                    [
                        0.5345132743362832,
                        0.6176991150442478
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7381946515472941,
                    [
                        0.7010317675999752,
                        0.7744730920639258
                    ]
                ],
                "accuracy": [
                    0.7486725663716814,
                    [
                        0.7132743362831858,
                        0.7823008849557522
                    ]
                ],
                "precision": [
                    0.7565708325345438,
                    [
                        0.718679448465053,
                        0.789756098777566
                    ]
                ],
                "recall": [
                    0.7486725663716814,
                    [
                        0.7132743362831858,
                        0.7823008849557522
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6329051916614888,
                    [
                        0.5903963741861511,
                        0.6716204765853633
                    ]
                ],
                "accuracy": [
                    0.6336283185840708,
                    [
                        0.5946563724057417,
                        0.672566371681416
                    ]
                ],
                "precision": [
                    0.6776481948522025,
                    [
                        0.6349870271239625,
                        0.7164915523726231
                    ]
                ],
                "recall": [
                    0.6336283185840708,
                    [
                        0.5946563724057417,
                        0.672566371681416
                    ]
                ]
            }
        }
    },
    "gpt-4o-mini": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6961593982494001,
                    [
                        0.6586272836784494,
                        0.7344071507786489
                    ]
                ],
                "accuracy": [
                    0.6938053097345133,
                    [
                        0.6548672566371682,
                        0.7327433628318584
                    ]
                ],
                "precision": [
                    0.7106950619083076,
                    [
                        0.6709937468612729,
                        0.7494310118436361
                    ]
                ],
                "recall": [
                    0.6938053097345133,
                    [
                        0.6548672566371682,
                        0.7327433628318584
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7489804465289308,
                    [
                        0.7135403150373493,
                        0.7852369318434869
                    ]
                ],
                "accuracy": [
                    0.7486725663716814,
                    [
                        0.7115044247787611,
                        0.784070796460177
                    ]
                ],
                "precision": [
                    0.7493639010547157,
                    [
                        0.7095160069471845,
                        0.78440105435548
                    ]
                ],
                "recall": [
                    0.7486725663716814,
                    [
                        0.7115044247787611,
                        0.784070796460177
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7083949177191582,
                    [
                        0.6712522254643184,
                        0.7431615230650552
                    ]
                ],
                "accuracy": [
                    0.7061946902654868,
                    [
                        0.6690265486725664,
                        0.7415929203539823
                    ]
                ],
                "precision": [
                    0.7254732161427898,
                    [
                        0.6852631291815002,
                        0.7601436211713035
                    ]
                ],
                "recall": [
                    0.7061946902654868,
                    [
                        0.6690265486725664,
                        0.7415929203539823
                    ]
                ]
            }
        }
    },
    "Llama-2-70b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5486285457520649,
                    [
                        0.5032349585831002,
                        0.5927390341506015
                    ]
                ],
                "accuracy": [
                    0.5663716814159292,
                    [
                        0.524390203061038,
                        0.6070796460176991
                    ]
                ],
                "precision": [
                    0.6798948131411163,
                    [
                        0.6289515081698891,
                        0.7186309524600264
                    ]
                ],
                "recall": [
                    0.5663716814159292,
                    [
                        0.524390203061038,
                        0.6070796460176991
                    ]
                ]
            }
        }
    },
    "MeLLaMA-70B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.49933667413107585,
                    [
                        0.4562479594068111,
                        0.5453590377365025
                    ]
                ],
                "accuracy": [
                    0.5026548672566372,
                    [
                        0.46017699115044247,
                        0.5451327433628319
                    ]
                ],
                "precision": [
                    0.5866075594446234,
                    [
                        0.537940147540624,
                        0.6345971219144616
                    ]
                ],
                "recall": [
                    0.5026548672566372,
                    [
                        0.46017699115044247,
                        0.5451327433628319
                    ]
                ]
            }
        }
    },
    "Med-LLaMA3-8B": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.003524695560093791,
                    [
                        0.0,
                        0.017346467560852164
                    ]
                ],
                "accuracy": [
                    0.0017699115044247787,
                    [
                        0.0,
                        0.008849557522123894
                    ]
                ],
                "precision": [
                    0.41238938053097346,
                    [
                        0.0,
                        0.47256005633437226
                    ]
                ],
                "recall": [
                    0.0017699115044247787,
                    [
                        0.0,
                        0.008849557522123894
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "accuracy": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "precision": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "recall": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.03441487383108851,
                    [
                        0.017427480934608792,
                        0.060883477176062836
                    ]
                ],
                "accuracy": [
                    0.01592920353982301,
                    [
                        0.007079646017699115,
                        0.02831858407079646
                    ]
                ],
                "precision": [
                    0.6210141873858689,
                    [
                        0.3640256669271048,
                        0.8476813834244648
                    ]
                ],
                "recall": [
                    0.017699115044247787,
                    [
                        0.008849557522123894,
                        0.03185840707964602
                    ]
                ]
            }
        }
    },
    "Llama-2-13b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.4487775166756317,
                    [
                        0.40724345609825363,
                        0.49711494129816347
                    ]
                ],
                "accuracy": [
                    0.368141592920354,
                    [
                        0.32876244883616934,
                        0.41061946902654867
                    ]
                ],
                "precision": [
                    0.5865917190739475,
                    [
                        0.5379964653940383,
                        0.6385370337597341
                    ]
                ],
                "recall": [
                    0.368141592920354,
                    [
                        0.32876244883616934,
                        0.41061946902654867
                    ]
                ]
            }
        }
    },
    "medgemma-27b-text-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7151113424720921,
                    [
                        0.6774490588654131,
                        0.748846942497201
                    ]
                ],
                "accuracy": [
                    0.7168141592920354,
                    [
                        0.6814159292035398,
                        0.7504424778761062
                    ]
                ],
                "precision": [
                    0.7145791526568595,
                    [
                        0.6755691752414648,
                        0.7476959164260685
                    ]
                ],
                "recall": [
                    0.7168141592920354,
                    [
                        0.6814159292035398,
                        0.7504424778761062
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7239475488880553,
                    [
                        0.6848225692463984,
                        0.7577139307568229
                    ]
                ],
                "accuracy": [
                    0.727433628318584,
                    [
                        0.6884955752212389,
                        0.7592920353982301
                    ]
                ],
                "precision": [
                    0.7247110580812575,
                    [
                        0.6835454902173311,
                        0.7563496488977111
                    ]
                ],
                "recall": [
                    0.727433628318584,
                    [
                        0.6884955752212389,
                        0.7592920353982301
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.5617723604385818,
                    [
                        0.5196005663606218,
                        0.6025194462229967
                    ]
                ],
                "accuracy": [
                    0.5681415929203539,
                    [
                        0.5274336283185841,
                        0.6068001907164489
                    ]
                ],
                "precision": [
                    0.62439991533575,
                    [
                        0.5756462843602775,
                        0.6660179932102622
                    ]
                ],
                "recall": [
                    0.5681415929203539,
                    [
                        0.5274336283185841,
                        0.6068001907164489
                    ]
                ]
            }
        }
    },
    "gemma-3-27b-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6813217478750065,
                    [
                        0.6452633243545253,
                        0.7229328303552148
                    ]
                ],
                "accuracy": [
                    0.679646017699115,
                    [
                        0.6425353864084701,
                        0.720353982300885
                    ]
                ],
                "precision": [
                    0.6848645388324553,
                    [
                        0.6450016804002613,
                        0.7227036933485169
                    ]
                ],
                "recall": [
                    0.679646017699115,
                    [
                        0.6425353864084701,
                        0.720353982300885
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.6679649633804733,
                    [
                        0.6259171575229314,
                        0.7152117001922114
                    ]
                ],
                "accuracy": [
                    0.7008849557522124,
                    [
                        0.6619469026548672,
                        0.7415929203539823
                    ]
                ],
                "precision": [
                    0.7307724793970547,
                    [
                        0.6913327133731093,
                        0.7698692928980974
                    ]
                ],
                "recall": [
                    0.7008849557522124,
                    [
                        0.6619469026548672,
                        0.7415929203539823
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.5906227442685552,
                    [
                        0.549221409312481,
                        0.6311029531805414
                    ]
                ],
                "accuracy": [
                    0.5911504424778761,
                    [
                        0.5493846536950001,
                        0.6300884955752213
                    ]
                ],
                "precision": [
                    0.630809603858547,
                    [
                        0.5879429400068662,
                        0.6758277680924828
                    ]
                ],
                "recall": [
                    0.5911504424778761,
                    [
                        0.5493846536950001,
                        0.6300884955752213
                    ]
                ]
            }
        }
    }
}