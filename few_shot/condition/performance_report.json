{
    "gpt-4o-2024-08-06": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8804519652750367,
                    [
                        0.828790524373774,
                        0.9179217901183375
                    ]
                ],
                "accuracy": [
                    0.6666666666666666,
                    [
                        0.5729166666666666,
                        0.7604166666666666
                    ]
                ],
                "precision": [
                    0.8841346745626872,
                    [
                        0.8099194326282365,
                        0.9257830365948848
                    ]
                ],
                "recall": [
                    0.9058823529411765,
                    [
                        0.8588900965797454,
                        0.9433962264150944
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8751360250094949,
                    [
                        0.8243506799759056,
                        0.9156606830881614
                    ]
                ],
                "accuracy": [
                    0.6666666666666666,
                    [
                        0.5729166666666666,
                        0.75
                    ]
                ],
                "precision": [
                    0.8818576347144897,
                    [
                        0.8096555260578654,
                        0.9244084046273946
                    ]
                ],
                "recall": [
                    0.9,
                    [
                        0.8530760339630364,
                        0.9401197604790419
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8564920492073068,
                    [
                        0.795142853179157,
                        0.9038621371568898
                    ]
                ],
                "accuracy": [
                    0.65625,
                    [
                        0.5625,
                        0.7395833333333334
                    ]
                ],
                "precision": [
                    0.8922409719784475,
                    [
                        0.821479546390818,
                        0.931262714785737
                    ]
                ],
                "recall": [
                    0.8588235294117647,
                    [
                        0.8009893521347519,
                        0.9096385542168675
                    ]
                ]
            }
        }
    },
    "MeLLaMA-13B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.650160103256989,
                    [
                        0.57119985117311,
                        0.726564958038255
                    ]
                ],
                "accuracy": [
                    0.4166666666666667,
                    [
                        0.3229166666666667,
                        0.5104166666666666
                    ]
                ],
                "precision": [
                    0.7975522516698987,
                    [
                        0.727474787150903,
                        0.8510020845708076
                    ]
                ],
                "recall": [
                    0.6235294117647059,
                    [
                        0.5318791109658254,
                        0.7041420118343196
                    ]
                ]
            }
        }
    },
    "Med-LLaMA3-8B": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.14931051108968177,
                    [
                        0.08819506209015152,
                        0.22995925923472102
                    ]
                ],
                "accuracy": [
                    0.010416666666666666,
                    [
                        0.0,
                        0.0522952303276772
                    ]
                ],
                "precision": [
                    0.38378151260504195,
                    [
                        0.29018465400780213,
                        0.5152627846232233
                    ]
                ],
                "recall": [
                    0.09411764705882353,
                    [
                        0.051306764068036255,
                        0.1616362879507023
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5067928676847083,
                    [
                        0.42943054064324276,
                        0.5852726716029704
                    ]
                ],
                "accuracy": [
                    0.23958333333333334,
                    [
                        0.16666666666666666,
                        0.3229166666666667
                    ]
                ],
                "precision": [
                    0.7293513136479888,
                    [
                        0.644656613045129,
                        0.7994951643946098
                    ]
                ],
                "recall": [
                    0.4588235294117647,
                    [
                        0.3772455089820359,
                        0.5347429331014562
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.06037553390494567,
                    [
                        0.021610881098680573,
                        0.13110203944624285
                    ]
                ],
                "accuracy": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "precision": [
                    0.45205882352941174,
                    [
                        0.2031344510148931,
                        0.6896315701045848
                    ]
                ],
                "recall": [
                    0.03529411764705882,
                    [
                        0.012121212121212121,
                        0.08185202261091294
                    ]
                ]
            }
        }
    },
    "gpt-4o-mini": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8184358053627474,
                    [
                        0.7559056073222669,
                        0.8696626513716765
                    ]
                ],
                "accuracy": [
                    0.5,
                    [
                        0.40625,
                        0.6041666666666666
                    ]
                ],
                "precision": [
                    0.7699368464087575,
                    [
                        0.6927023402098034,
                        0.8251916703974461
                    ]
                ],
                "recall": [
                    0.9058823529411765,
                    [
                        0.8520719545244031,
                        0.9467507906020907
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7714918444627599,
                    [
                        0.7120312658795521,
                        0.8219914413663104
                    ]
                ],
                "accuracy": [
                    0.46875,
                    [
                        0.375,
                        0.5662085487942493
                    ]
                ],
                "precision": [
                    0.7583896946963486,
                    [
                        0.6869407557976178,
                        0.812592178310452
                    ]
                ],
                "recall": [
                    0.8529411764705882,
                    [
                        0.7988116101465041,
                        0.9
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8010274411102651,
                    [
                        0.7391984017998262,
                        0.8519978111296433
                    ]
                ],
                "accuracy": [
                    0.4895833333333333,
                    [
                        0.3958333333333333,
                        0.5833333333333334
                    ]
                ],
                "precision": [
                    0.782592809489361,
                    [
                        0.7068879084564934,
                        0.8321802954988222
                    ]
                ],
                "recall": [
                    0.8647058823529412,
                    [
                        0.8074296597936035,
                        0.9129705897835252
                    ]
                ]
            }
        }
    },
    "medgemma-27b-text-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8156442247594612,
                    [
                        0.7528807072696823,
                        0.8668951035951467
                    ]
                ],
                "accuracy": [
                    0.5833333333333334,
                    [
                        0.4895833333333333,
                        0.6875
                    ]
                ],
                "precision": [
                    0.8108824437387047,
                    [
                        0.7500194098143563,
                        0.8648243783444748
                    ]
                ],
                "recall": [
                    0.8764705882352941,
                    [
                        0.8232301494226418,
                        0.9186046511627907
                    ]
                ]
            }
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8021638767937592,
                    [
                        0.7436957621623115,
                        0.8496273850900751
                    ]
                ],
                "accuracy": [
                    0.3958333333333333,
                    [
                        0.3020833333333333,
                        0.49858592231836596
                    ]
                ],
                "precision": [
                    0.8186288874524169,
                    [
                        0.745918917101093,
                        0.8721559013871109
                    ]
                ],
                "recall": [
                    0.8588235294117647,
                    [
                        0.8072024584555979,
                        0.9023062338716119
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8257930355222062,
                    [
                        0.7733298877196505,
                        0.8682731767877484
                    ]
                ],
                "accuracy": [
                    0.4166666666666667,
                    [
                        0.3333333333333333,
                        0.5208333333333334
                    ]
                ],
                "precision": [
                    0.8290885258532317,
                    [
                        0.7635878445331817,
                        0.8734526616084788
                    ]
                ],
                "recall": [
                    0.888235294117647,
                    [
                        0.84,
                        0.9294117647058824
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7572676477643293,
                    [
                        0.6927055138103387,
                        0.8147842147187421
                    ]
                ],
                "accuracy": [
                    0.34375,
                    [
                        0.25,
                        0.4479166666666667
                    ]
                ],
                "precision": [
                    0.7481071124101815,
                    [
                        0.6703342321518191,
                        0.8098228723986953
                    ]
                ],
                "recall": [
                    0.8470588235294118,
                    [
                        0.7916666666666666,
                        0.8943582813514824
                    ]
                ]
            }
        }
    },
    "Llama-3.1-8B-Instruct": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.7592886951622332,
                    [
                        0.6931145243921789,
                        0.812616186756378
                    ]
                ],
                "accuracy": [
                    0.2916666666666667,
                    [
                        0.20833333333333334,
                        0.3854166666666667
                    ]
                ],
                "precision": [
                    0.7467182105278343,
                    [
                        0.6683115048297296,
                        0.8011318037758902
                    ]
                ],
                "recall": [
                    0.8588235294117647,
                    [
                        0.7965062976572193,
                        0.9041167721193304
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7584853944115878,
                    [
                        0.6960975769319977,
                        0.8112516069137787
                    ]
                ],
                "accuracy": [
                    0.3645833333333333,
                    [
                        0.2708333333333333,
                        0.46875
                    ]
                ],
                "precision": [
                    0.7637353165728039,
                    [
                        0.6912852808532364,
                        0.8114273960880146
                    ]
                ],
                "recall": [
                    0.8529411764705882,
                    [
                        0.802588210115842,
                        0.8963969820632555
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7303023895808833,
                    [
                        0.6656802410249514,
                        0.7896703452436048
                    ]
                ],
                "accuracy": [
                    0.2708333333333333,
                    [
                        0.1875,
                        0.3645833333333333
                    ]
                ],
                "precision": [
                    0.7019321739390942,
                    [
                        0.6276004929366471,
                        0.7509936337783407
                    ]
                ],
                "recall": [
                    0.8588235294117647,
                    [
                        0.7909977486357601,
                        0.9089184373635443
                    ]
                ]
            }
        }
    },
    "tuned": {
        "instruction_8b": {
            "metrics": {
                "f1-weighted": [
                    0.9142206479337867,
                    [
                        0.8703539150723648,
                        0.9497703233427163
                    ]
                ],
                "accuracy": [
                    0.8229166666666666,
                    [
                        0.75,
                        0.8854166666666666
                    ]
                ],
                "precision": [
                    0.9088361422742358,
                    [
                        0.837371238264898,
                        0.9501110394570021
                    ]
                ],
                "recall": [
                    0.9235294117647059,
                    [
                        0.8729405024672782,
                        0.9586217720127825
                    ]
                ]
            }
        }
    },
    "Llama-2-13b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6177650898433569,
                    [
                        0.5484189351022521,
                        0.6847026956241935
                    ]
                ],
                "accuracy": [
                    0.3229166666666667,
                    [
                        0.22916666666666666,
                        0.4166666666666667
                    ]
                ],
                "precision": [
                    0.6829355044863473,
                    [
                        0.6098688095650241,
                        0.7236084186987435
                    ]
                ],
                "recall": [
                    0.7235294117647059,
                    [
                        0.6572293990993726,
                        0.7854036153593733
                    ]
                ]
            }
        }
    },
    "Llama-2-70b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6639340858831774,
                    [
                        0.5846636298531601,
                        0.7336962444141568
                    ]
                ],
                "accuracy": [
                    0.3541666666666667,
                    [
                        0.2604166666666667,
                        0.4479166666666667
                    ]
                ],
                "precision": [
                    0.7558498364380717,
                    [
                        0.6993570893582792,
                        0.7930342802048933
                    ]
                ],
                "recall": [
                    0.7352941176470589,
                    [
                        0.6705882352941176,
                        0.8047745893989585
                    ]
                ]
            }
        }
    },
    "MeLLaMA-70B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8013267701047847,
                    [
                        0.7314842126779909,
                        0.8518524936187689
                    ]
                ],
                "accuracy": [
                    0.53125,
                    [
                        0.4307786229528154,
                        0.625
                    ]
                ],
                "precision": [
                    0.8318853435273313,
                    [
                        0.7558188286749832,
                        0.8756166921976574
                    ]
                ],
                "recall": [
                    0.8294117647058824,
                    [
                        0.7664059571104967,
                        0.881023620911537
                    ]
                ]
            }
        }
    }
}