{
    "Med-LLaMA3-8B": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.0967322404468434,
                    [
                        0.05100762543617326,
                        0.16688561862527437
                    ]
                ],
                "accuracy": [
                    0.010638297872340425,
                    [
                        0.0,
                        0.04869779502342182
                    ]
                ],
                "precision": [
                    0.4444112725960434,
                    [
                        0.21644760865759038,
                        0.5735479169877353
                    ]
                ],
                "recall": [
                    0.0736196319018405,
                    [
                        0.03864630845498574,
                        0.1251258874519697
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.03516161523669993,
                    [
                        0.011190848013914647,
                        0.09219750570682242
                    ]
                ],
                "accuracy": [
                    0.010638297872340425,
                    [
                        0.0,
                        0.04869779502342182
                    ]
                ],
                "precision": [
                    0.39263803680981596,
                    [
                        0.0,
                        0.45569620253164556
                    ]
                ],
                "recall": [
                    0.018404907975460124,
                    [
                        0.0056179775280898875,
                        0.05192133232357153
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "accuracy": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "precision": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ],
                "recall": [
                    0.0,
                    [
                        NaN,
                        NaN
                    ]
                ]
            }
        }
    },
    "gpt-4o-mini": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7928407615085352,
                    [
                        0.7378078567927413,
                        0.8317673822105215
                    ]
                ],
                "accuracy": [
                    0.19148936170212766,
                    [
                        0.11702127659574468,
                        0.2872340425531915
                    ]
                ],
                "precision": [
                    0.7480208952601591,
                    [
                        0.6690346140211294,
                        0.789585679636424
                    ]
                ],
                "recall": [
                    0.901840490797546,
                    [
                        0.8506332068877892,
                        0.9393946834651393
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.7883644491619965,
                    [
                        0.7423575757587103,
                        0.8248365653325933
                    ]
                ],
                "accuracy": [
                    0.1595744680851064,
                    [
                        0.09574468085106383,
                        0.2553191489361702
                    ]
                ],
                "precision": [
                    0.7288438533611755,
                    [
                        0.6655997169473612,
                        0.7693559794395144
                    ]
                ],
                "recall": [
                    0.9263803680981595,
                    [
                        0.8825574307153244,
                        0.9584431358551856
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7737694416062537,
                    [
                        0.6966422010290604,
                        0.8296340336442058
                    ]
                ],
                "accuracy": [
                    0.1746031746031746,
                    [
                        0.09523809523809523,
                        0.2857142857142857
                    ]
                ],
                "precision": [
                    0.7075413196952989,
                    [
                        0.6006895380973811,
                        0.7746665386991937
                    ]
                ],
                "recall": [
                    0.9019607843137255,
                    [
                        0.8247422680412371,
                        0.9454545454545454
                    ]
                ]
            }
        }
    },
    "tuned": {
        "instruction_8b": {
            "metrics": {
                "f1-weighted": [
                    0.7706193569828876,
                    [
                        0.7079600824589662,
                        0.8275971748342056
                    ]
                ],
                "accuracy": [
                    0.5,
                    [
                        0.39361702127659576,
                        0.5851063829787234
                    ]
                ],
                "precision": [
                    0.8322572791897945,
                    [
                        0.7530785275695938,
                        0.8835239947225411
                    ]
                ],
                "recall": [
                    0.7423312883435583,
                    [
                        0.6674870597650708,
                        0.8076584736810027
                    ]
                ]
            }
        }
    },
    "medgemma-27b-text-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8711662732613927,
                    [
                        0.8351613674818106,
                        0.8998562221456948
                    ]
                ],
                "accuracy": [
                    0.5319148936170213,
                    [
                        0.43617021276595747,
                        0.6382978723404256
                    ]
                ],
                "precision": [
                    0.8107633845363906,
                    [
                        0.7555648739320047,
                        0.8484439427630868
                    ]
                ],
                "recall": [
                    0.950920245398773,
                    [
                        0.9091832942206937,
                        0.9753086419753086
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8474760288358159,
                    [
                        0.8085901625215804,
                        0.87740933475944
                    ]
                ],
                "accuracy": [
                    0.43617021276595747,
                    [
                        0.3404255319148936,
                        0.5425531914893617
                    ]
                ],
                "precision": [
                    0.7784125978028287,
                    [
                        0.7129444093166986,
                        0.8185456752261742
                    ]
                ],
                "recall": [
                    0.950920245398773,
                    [
                        0.9135802469135802,
                        0.9771428571428571
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8301140358830225,
                    [
                        0.7860381305458294,
                        0.866519221878069
                    ]
                ],
                "accuracy": [
                    0.48936170212765956,
                    [
                        0.4002606332035507,
                        0.5957446808510638
                    ]
                ],
                "precision": [
                    0.7994319472847079,
                    [
                        0.7470393262543636,
                        0.8373087793765939
                    ]
                ],
                "recall": [
                    0.8895705521472392,
                    [
                        0.8288202269238373,
                        0.9325153374233128
                    ]
                ]
            }
        }
    },
    "Llama-3.1-8B-Instruct": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.7479419876463772,
                    [
                        0.6892713643858913,
                        0.8002182919855942
                    ]
                ],
                "accuracy": [
                    0.19148936170212766,
                    [
                        0.11702127659574468,
                        0.2765957446808511
                    ]
                ],
                "precision": [
                    0.747597572513464,
                    [
                        0.6856360135497777,
                        0.7896120288583587
                    ]
                ],
                "recall": [
                    0.8343558282208589,
                    [
                        0.7761977182279414,
                        0.8902439024390244
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7531100918450191,
                    [
                        0.6894965900242722,
                        0.8041743330103215
                    ]
                ],
                "accuracy": [
                    0.2553191489361702,
                    [
                        0.18085106382978725,
                        0.35106382978723405
                    ]
                ],
                "precision": [
                    0.7736401422645859,
                    [
                        0.6898800445198426,
                        0.8187285720722652
                    ]
                ],
                "recall": [
                    0.8343558282208589,
                    [
                        0.76165602889917,
                        0.8851133968169527
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7369779148577178,
                    [
                        0.6766831487018554,
                        0.7864713878852582
                    ]
                ],
                "accuracy": [
                    0.20212765957446807,
                    [
                        0.1276595744680851,
                        0.2978723404255319
                    ]
                ],
                "precision": [
                    0.745233144676154,
                    [
                        0.659972684648349,
                        0.7910330593647362
                    ]
                ],
                "recall": [
                    0.7975460122699386,
                    [
                        0.7370481452531449,
                        0.8486100275660767
                    ]
                ]
            }
        }
    },
    "gpt-4o-2024-08-06": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.8606566551120366,
                    [
                        0.8215794100193248,
                        0.8966013348533414
                    ]
                ],
                "accuracy": [
                    0.5425531914893617,
                    [
                        0.44680851063829785,
                        0.648936170212766
                    ]
                ],
                "precision": [
                    0.8412934689569961,
                    [
                        0.7770008445367041,
                        0.8795354765491138
                    ]
                ],
                "recall": [
                    0.901840490797546,
                    [
                        0.8494955719575985,
                        0.9392009685095148
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8429208330701157,
                    [
                        0.8024913654065003,
                        0.8768857230199851
                    ]
                ],
                "accuracy": [
                    0.4574468085106383,
                    [
                        0.35106382978723405,
                        0.5531914893617021
                    ]
                ],
                "precision": [
                    0.8048029850177089,
                    [
                        0.7436972114090886,
                        0.845763197885205
                    ]
                ],
                "recall": [
                    0.9141104294478528,
                    [
                        0.861271676300578,
                        0.9492760529375271
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8584727386148271,
                    [
                        0.8217725738923147,
                        0.8876705905733799
                    ]
                ],
                "accuracy": [
                    0.5,
                    [
                        0.40425531914893614,
                        0.5957446808510638
                    ]
                ],
                "precision": [
                    0.8170522759122641,
                    [
                        0.7578235383536149,
                        0.8585553626180917
                    ]
                ],
                "recall": [
                    0.9202453987730062,
                    [
                        0.8692778407565392,
                        0.9548387096774194
                    ]
                ]
            }
        }
    },
    "MeLLaMA-70B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7988382403847453,
                    [
                        0.7394043780384275,
                        0.8405644192392744
                    ]
                ],
                "accuracy": [
                    0.4787234042553192,
                    [
                        0.3723404255319149,
                        0.5851063829787234
                    ]
                ],
                "precision": [
                    0.7727024359976709,
                    [
                        0.7020672116319455,
                        0.8186402231735674
                    ]
                ],
                "recall": [
                    0.8466257668711656,
                    [
                        0.7699897418148731,
                        0.8990920624860416
                    ]
                ]
            }
        }
    },
    "Llama-2-13b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5605248114089687,
                    [
                        0.47760870433337166,
                        0.6300023591634487
                    ]
                ],
                "accuracy": [
                    0.2978723404255319,
                    [
                        0.2127659574468085,
                        0.39361702127659576
                    ]
                ],
                "precision": [
                    0.6480639281586201,
                    [
                        0.5609288626553349,
                        0.7303853889958578
                    ]
                ],
                "recall": [
                    0.6073619631901841,
                    [
                        0.5238774390028919,
                        0.6708860759493671
                    ]
                ]
            }
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7558313812344816,
                    [
                        0.6958040815199218,
                        0.8047018767560663
                    ]
                ],
                "accuracy": [
                    0.2872340425531915,
                    [
                        0.2127659574468085,
                        0.39361702127659576
                    ]
                ],
                "precision": [
                    0.7673156777451255,
                    [
                        0.6917272596322563,
                        0.8171144154303818
                    ]
                ],
                "recall": [
                    0.8098159509202454,
                    [
                        0.7421383647798742,
                        0.8674543120316375
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.6403175716111404,
                    [
                        0.5753830352310448,
                        0.7150248814830046
                    ]
                ],
                "accuracy": [
                    0.20212765957446807,
                    [
                        0.13829787234042554,
                        0.29754376203499316
                    ]
                ],
                "precision": [
                    0.7088630057850802,
                    [
                        0.607826361384926,
                        0.8053265066981418
                    ]
                ],
                "recall": [
                    0.656441717791411,
                    [
                        0.5723739072542599,
                        0.7333108161019232
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.7228138999349991,
                    [
                        0.6646807733768857,
                        0.7709817830942803
                    ]
                ],
                "accuracy": [
                    0.19148936170212766,
                    [
                        0.1276595744680851,
                        0.2765957446808511
                    ]
                ],
                "precision": [
                    0.732084899490827,
                    [
                        0.6485537807364047,
                        0.782203025870403
                    ]
                ],
                "recall": [
                    0.8098159509202454,
                    [
                        0.7412349803584326,
                        0.8627450980392157
                    ]
                ]
            }
        }
    },
    "MeLLaMA-13B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5063781120439367,
                    [
                        0.4335858427253622,
                        0.5656934838989887
                    ]
                ],
                "accuracy": [
                    0.2765957446808511,
                    [
                        0.19148936170212766,
                        0.3723404255319149
                    ]
                ],
                "precision": [
                    0.5778469707049054,
                    [
                        0.4869082913797592,
                        0.6503043035611447
                    ]
                ],
                "recall": [
                    0.5214723926380368,
                    [
                        0.4487185164838142,
                        0.5827287410930396
                    ]
                ]
            }
        }
    },
    "Llama-2-70b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.7326350954483852,
                    [
                        0.6836129834184789,
                        0.7713651566027572
                    ]
                ],
                "accuracy": [
                    0.24468085106382978,
                    [
                        0.1702127659574468,
                        0.3404255319148936
                    ]
                ],
                "precision": [
                    0.7038425558334517,
                    [
                        0.6310090026782195,
                        0.7517433040200644
                    ]
                ],
                "recall": [
                    0.8159509202453987,
                    [
                        0.760378229436432,
                        0.8675496688741722
                    ]
                ]
            }
        }
    },
    "gemma-3-27b-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.8346659302640443,
                    [
                        0.7961334872912383,
                        0.8628610211431055
                    ]
                ],
                "accuracy": [
                    0.3829787234042553,
                    [
                        0.2872340425531915,
                        0.4787234042553192
                    ]
                ],
                "precision": [
                    0.7509767070518462,
                    [
                        0.6924939109027999,
                        0.7885384689916782
                    ]
                ],
                "recall": [
                    0.9570552147239264,
                    [
                        0.9213676757579199,
                        0.9805194805194806
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.8032757364837972,
                    [
                        0.7585267588732345,
                        0.8373904100999189
                    ]
                ],
                "accuracy": [
                    0.32978723404255317,
                    [
                        0.23861039712803184,
                        0.425531914893617
                    ]
                ],
                "precision": [
                    0.7181031177646366,
                    [
                        0.6469784791659192,
                        0.7650661281481144
                    ]
                ],
                "recall": [
                    0.9447852760736196,
                    [
                        0.8953375709323618,
                        0.9741935483870968
                    ]
                ]
            }
        }
    }
}