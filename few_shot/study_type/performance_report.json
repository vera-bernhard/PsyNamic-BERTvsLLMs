{
    "gpt-4o-2024-08-06": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6251156639772691,
                    [
                        0.5137284147337524,
                        0.7260509802998129
                    ]
                ],
                "accuracy": [
                    0.6391752577319587,
                    [
                        0.5360824742268041,
                        0.7319587628865979
                    ]
                ],
                "precision": [
                    0.7857270058572283,
                    [
                        0.5927604284050798,
                        0.830368696376517
                    ]
                ],
                "recall": [
                    0.6391752577319587,
                    [
                        0.5360824742268041,
                        0.7319587628865979
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6410489281623302,
                    [
                        0.5307979997700163,
                        0.7372838736103088
                    ]
                ],
                "accuracy": [
                    0.6494845360824743,
                    [
                        0.5567010309278351,
                        0.7422680412371134
                    ]
                ],
                "precision": [
                    0.7890938686923494,
                    [
                        0.6203898399096586,
                        0.8325439363511378
                    ]
                ],
                "recall": [
                    0.6494845360824743,
                    [
                        0.5567010309278351,
                        0.7422680412371134
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.6751431844215349,
                    [
                        0.5667003522197789,
                        0.7677460036325625
                    ]
                ],
                "accuracy": [
                    0.6804123711340206,
                    [
                        0.5773195876288659,
                        0.7731958762886598
                    ]
                ],
                "precision": [
                    0.8168746608790015,
                    [
                        0.6457548970289537,
                        0.8501624982731375
                    ]
                ],
                "recall": [
                    0.6804123711340206,
                    [
                        0.5773195876288659,
                        0.7731958762886598
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.09415807560137457,
                    [
                        0.04338319593043228,
                        0.1772168925461335
                    ]
                ],
                "accuracy": [
                    0.061855670103092786,
                    [
                        0.020618556701030927,
                        0.12371134020618557
                    ]
                ],
                "precision": [
                    0.12285223367697595,
                    [
                        0.04498594189315838,
                        0.26055796098841244
                    ]
                ],
                "recall": [
                    0.08247422680412371,
                    [
                        0.041237113402061855,
                        0.15463917525773196
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 72
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.32536633151935845,
                    [
                        0.22899658984446908,
                        0.43262312631202227
                    ]
                ],
                "accuracy": [
                    0.23711340206185566,
                    [
                        0.15463917525773196,
                        0.32989690721649484
                    ]
                ],
                "precision": [
                    0.7700455449777208,
                    [
                        0.30275537878757863,
                        0.8536082474226804
                    ]
                ],
                "recall": [
                    0.27835051546391754,
                    [
                        0.1958762886597938,
                        0.3711340206185567
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 42
        }
    },
    "Llama-3.1-8B-Instruct": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.5641489310500832,
                    [
                        0.4525002268633453,
                        0.6684937975960354
                    ]
                ],
                "accuracy": [
                    0.5360824742268041,
                    [
                        0.4329896907216495,
                        0.6391752577319587
                    ]
                ],
                "precision": [
                    0.7990549828178694,
                    [
                        0.6096540923384454,
                        0.8339734616053848
                    ]
                ],
                "recall": [
                    0.5773195876288659,
                    [
                        0.4742268041237113,
                        0.6701030927835051
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.4619529141504182,
                    [
                        0.34983498407072494,
                        0.5774166192363598
                    ]
                ],
                "accuracy": [
                    0.4639175257731959,
                    [
                        0.36082474226804123,
                        0.5670103092783505
                    ]
                ],
                "precision": [
                    0.7721993127147767,
                    [
                        0.5883739673065554,
                        0.8065747525852713
                    ]
                ],
                "recall": [
                    0.5257731958762887,
                    [
                        0.422680412371134,
                        0.6288659793814433
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        }
    },
    "MeLLaMA-13B-chat": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.3825535129270739,
                    [
                        0.2838235624539495,
                        0.49809540599419616
                    ]
                ],
                "accuracy": [
                    0.29896907216494845,
                    [
                        0.21649484536082475,
                        0.4020618556701031
                    ]
                ],
                "precision": [
                    0.6829444745885332,
                    [
                        0.5234016501317437,
                        0.8939527531191923
                    ]
                ],
                "recall": [
                    0.31958762886597936,
                    [
                        0.23711340206185566,
                        0.422680412371134
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 29
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.1820018777288596,
                    [
                        0.10573142041849283,
                        0.29031695438945526
                    ]
                ],
                "accuracy": [
                    0.13402061855670103,
                    [
                        0.07216494845360824,
                        0.21649484536082475
                    ]
                ],
                "precision": [
                    0.740979381443299,
                    [
                        0.36082474226804123,
                        0.8309755250418793
                    ]
                ],
                "recall": [
                    0.13402061855670103,
                    [
                        0.07216494845360824,
                        0.21649484536082475
                    ]
                ]
            },
            "nr_faulty_parsable": 3,
            "nr_non_parsable": 66
        }
    },
    "gpt-4o-mini": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5364780231530831,
                    [
                        0.4212443872596678,
                        0.6467259670318575
                    ]
                ],
                "accuracy": [
                    0.5360824742268041,
                    [
                        0.44329896907216493,
                        0.6391752577319587
                    ]
                ],
                "precision": [
                    0.8043262150220913,
                    [
                        0.6430651007888175,
                        0.8360793423268461
                    ]
                ],
                "recall": [
                    0.5463917525773195,
                    [
                        0.44329896907216493,
                        0.6494845360824743
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.556430939216694,
                    [
                        0.4435411276989492,
                        0.6652121256895854
                    ]
                ],
                "accuracy": [
                    0.5670103092783505,
                    [
                        0.4639175257731959,
                        0.6661670647002201
                    ]
                ],
                "precision": [
                    0.804581901489118,
                    [
                        0.6287722780534712,
                        0.8367897900758756
                    ]
                ],
                "recall": [
                    0.5773195876288659,
                    [
                        0.4742268041237113,
                        0.6804123711340206
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.5721396806145138,
                    [
                        0.4617389269629657,
                        0.6737017096330093
                    ]
                ],
                "accuracy": [
                    0.5463917525773195,
                    [
                        0.44329896907216493,
                        0.6391752577319587
                    ]
                ],
                "precision": [
                    0.8125829758169516,
                    [
                        0.6096024087248767,
                        0.8618467306820541
                    ]
                ],
                "recall": [
                    0.5670103092783505,
                    [
                        0.4639175257731959,
                        0.6597938144329897
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        }
    },
    "Llama-2-13b-chat-hf": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.16379269233466584,
                    [
                        0.08905380334457662,
                        0.27115572170539787
                    ]
                ],
                "accuracy": [
                    0.09278350515463918,
                    [
                        0.041237113402061855,
                        0.16494845360824742
                    ]
                ],
                "precision": [
                    0.493127147766323,
                    [
                        0.3251572643863679,
                        0.8187741753077146
                    ]
                ],
                "recall": [
                    0.10309278350515463,
                    [
                        0.05154639175257732,
                        0.17525773195876287
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 77
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.5545357691223013,
                    [
                        0.45274573668981033,
                        0.6553342135974644
                    ]
                ],
                "accuracy": [
                    0.5360824742268041,
                    [
                        0.4329896907216495,
                        0.6288659793814433
                    ]
                ],
                "precision": [
                    0.5942459240885719,
                    [
                        0.4698174235475463,
                        0.6776472548350132
                    ]
                ],
                "recall": [
                    0.5773195876288659,
                    [
                        0.4742268041237113,
                        0.6701030927835051
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 2
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.4919000100701132,
                    [
                        0.38633522537652526,
                        0.5951564066020716
                    ]
                ],
                "accuracy": [
                    0.5257731958762887,
                    [
                        0.422680412371134,
                        0.6288659793814433
                    ]
                ],
                "precision": [
                    0.4652815374248062,
                    [
                        0.3500190807804889,
                        0.5662133449898619
                    ]
                ],
                "recall": [
                    0.5463917525773195,
                    [
                        0.44329896907216493,
                        0.6494845360824743
                    ]
                ]
            },
            "nr_faulty_parsable": 0,
            "nr_non_parsable": 0
        }
    },
    "Med-LLaMA3-8B": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.10263157894736841,
                    [
                        0.04810996563573883,
                        0.19351930147261265
                    ]
                ],
                "accuracy": [
                    0.08247422680412371,
                    [
                        0.041237113402061855,
                        0.15463917525773196
                    ]
                ],
                "precision": [
                    0.2263745704467354,
                    [
                        0.060269627279936566,
                        0.5629791463625758
                    ]
                ],
                "recall": [
                    0.08247422680412371,
                    [
                        0.041237113402061855,
                        0.15463917525773196
                    ]
                ]
            },
            "nr_faulty_parsable": 19,
            "nr_non_parsable": 78
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.1480227727342668,
                    [
                        0.08247422680412371,
                        0.23587832216397292
                    ]
                ],
                "accuracy": [
                    0.13402061855670103,
                    [
                        0.07216494845360824,
                        0.21649484536082475
                    ]
                ],
                "precision": [
                    0.1652920962199313,
                    [
                        0.08513468573328899,
                        0.2860257808775743
                    ]
                ],
                "recall": [
                    0.13402061855670103,
                    [
                        0.07216494845360824,
                        0.21649484536082475
                    ]
                ]
            },
            "nr_faulty_parsable": 35,
            "nr_non_parsable": 62
        }
    }
}