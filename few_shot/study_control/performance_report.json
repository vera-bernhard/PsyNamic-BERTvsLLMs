{
    "Meta-Llama-3-8B-Instruct": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.5948165764583675,
                    [
                        0.5003947280471219,
                        0.6856678030693149
                    ]
                ],
                "accuracy": [
                    0.30612244897959184,
                    [
                        0.23469387755102042,
                        0.40816326530612246
                    ]
                ],
                "precision": [
                    0.6201101256467111,
                    [
                        0.4825322251838318,
                        0.714460184143667
                    ]
                ],
                "recall": [
                    0.71,
                    [
                        0.6161616161616161,
                        0.7878787878787878
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5635912742295721,
                    [
                        0.46571033781627275,
                        0.6420279128041408
                    ]
                ],
                "accuracy": [
                    0.29591836734693877,
                    [
                        0.20408163265306123,
                        0.3877551020408163
                    ]
                ],
                "precision": [
                    0.5751174472817656,
                    [
                        0.4511312400823372,
                        0.6659729382451695
                    ]
                ],
                "recall": [
                    0.65,
                    [
                        0.5490291287458813,
                        0.7351156234595859
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6467982434308769,
                    [
                        0.5564090021063238,
                        0.7329749941642594
                    ]
                ],
                "accuracy": [
                    0.32653061224489793,
                    [
                        0.24489795918367346,
                        0.42857142857142855
                    ]
                ],
                "precision": [
                    0.6361493247184459,
                    [
                        0.5287145980393285,
                        0.7262312472432655
                    ]
                ],
                "recall": [
                    0.72,
                    [
                        0.6302057662246003,
                        0.8080808080808081
                    ]
                ]
            }
        }
    },
    "MeLLaMA-13B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.48453644117076955,
                    [
                        0.38583621104465027,
                        0.586035466180341
                    ]
                ],
                "accuracy": [
                    0.5,
                    [
                        0.40816326530612246,
                        0.5918367346938775
                    ]
                ],
                "precision": [
                    0.530989898989899,
                    [
                        0.40184314414732747,
                        0.6306988388493945
                    ]
                ],
                "recall": [
                    0.53,
                    [
                        0.43564356435643564,
                        0.63
                    ]
                ]
            }
        }
    },
    "Llama-3.1-8B-Instruct": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6538375557455951,
                    [
                        0.5704588078531742,
                        0.7238279052487059
                    ]
                ],
                "accuracy": [
                    0.47959183673469385,
                    [
                        0.3877551020408163,
                        0.5816326530612245
                    ]
                ],
                "precision": [
                    0.6477992801771871,
                    [
                        0.5576685100117845,
                        0.717859030014582
                    ]
                ],
                "recall": [
                    0.71,
                    [
                        0.62,
                        0.788446788619553
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7152478632478634,
                    [
                        0.6346295088406022,
                        0.7852563515559239
                    ]
                ],
                "accuracy": [
                    0.5816326530612245,
                    [
                        0.47959183673469385,
                        0.673469387755102
                    ]
                ],
                "precision": [
                    0.7030840336134454,
                    [
                        0.6222764763099949,
                        0.7632454742398824
                    ]
                ],
                "recall": [
                    0.77,
                    [
                        0.6831683168316832,
                        0.8415841584158416
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6850714285714286,
                    [
                        0.5875493177878106,
                        0.7597170486520168
                    ]
                ],
                "accuracy": [
                    0.5612244897959183,
                    [
                        0.45918367346938777,
                        0.6632653061224489
                    ]
                ],
                "precision": [
                    0.6628484624763695,
                    [
                        0.5533232141834243,
                        0.732444542040583
                    ]
                ],
                "recall": [
                    0.75,
                    [
                        0.6566763228906757,
                        0.83
                    ]
                ]
            }
        }
    },
    "tuned": {
        "instruction_8b": {
            "metrics": {
                "f1-weighted": [
                    0.7707894865631415,
                    [
                        0.6913352064360416,
                        0.8464372247939655
                    ]
                ],
                "accuracy": [
                    0.7551020408163265,
                    [
                        0.673469387755102,
                        0.8367346938775511
                    ]
                ],
                "precision": [
                    0.7872860472860473,
                    [
                        0.6925072548914427,
                        0.8482456461698179
                    ]
                ],
                "recall": [
                    0.78,
                    [
                        0.7,
                        0.8514851485148515
                    ]
                ]
            }
        }
    },
    "Llama-2-13b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.2254732516021176,
                    [
                        0.1493340273060656,
                        0.33150526487789433
                    ]
                ],
                "accuracy": [
                    0.25510204081632654,
                    [
                        0.1836734693877551,
                        0.3469387755102041
                    ]
                ],
                "precision": [
                    0.47890610328638494,
                    [
                        0.198049346924231,
                        0.6597820718705208
                    ]
                ],
                "recall": [
                    0.28,
                    [
                        0.20202020202020202,
                        0.38
                    ]
                ]
            }
        }
    },
    "gpt-4o-mini": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.5992493432779811,
                    [
                        0.5120297232959657,
                        0.6791103569181105
                    ]
                ],
                "accuracy": [
                    0.40816326530612246,
                    [
                        0.3163265306122449,
                        0.5
                    ]
                ],
                "precision": [
                    0.6270476190476191,
                    [
                        0.4775667583910496,
                        0.7206854583566575
                    ]
                ],
                "recall": [
                    0.67,
                    [
                        0.58,
                        0.76
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.6284864813915213,
                    [
                        0.5409041779089755,
                        0.709093634921908
                    ]
                ],
                "accuracy": [
                    0.41836734693877553,
                    [
                        0.32653061224489793,
                        0.5142334985399912
                    ]
                ],
                "precision": [
                    0.6234760201039271,
                    [
                        0.5215025983403497,
                        0.6975892863308693
                    ]
                ],
                "recall": [
                    0.68,
                    [
                        0.5816326530612245,
                        0.7676767676767676
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6592343976710873,
                    [
                        0.5747428839672344,
                        0.7228405578804791
                    ]
                ],
                "accuracy": [
                    0.37755102040816324,
                    [
                        0.2857142857142857,
                        0.47959183673469385
                    ]
                ],
                "precision": [
                    0.6704761904761906,
                    [
                        0.5581149110802116,
                        0.7358724347886402
                    ]
                ],
                "recall": [
                    0.73,
                    [
                        0.6416186276880321,
                        0.8080808080808081
                    ]
                ]
            }
        }
    },
    "Llama-2-70b-chat-hf": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6322927919538088,
                    [
                        0.5223084080024433,
                        0.7288153204153156
                    ]
                ],
                "accuracy": [
                    0.6224489795918368,
                    [
                        0.5102040816326531,
                        0.7040816326530612
                    ]
                ],
                "precision": [
                    0.7476272022551094,
                    [
                        0.6423857440093045,
                        0.8106133093693894
                    ]
                ],
                "recall": [
                    0.64,
                    [
                        0.5302471415602577,
                        0.7271151589504513
                    ]
                ]
            }
        }
    },
    "Med-LLaMA3-8B": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.15354838709677418,
                    [
                        0.090017381898135,
                        0.2402218005550134
                    ]
                ],
                "accuracy": [
                    0.17346938775510204,
                    [
                        0.11224489795918367,
                        0.25510204081632654
                    ]
                ],
                "precision": [
                    0.12101694915254237,
                    [
                        0.06480639686628425,
                        0.20426546795519238
                    ]
                ],
                "recall": [
                    0.21,
                    [
                        0.14,
                        0.3
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.17800298062593142,
                    [
                        0.10643067999192254,
                        0.2663342980636508
                    ]
                ],
                "accuracy": [
                    0.2755102040816326,
                    [
                        0.19387755102040816,
                        0.3673469387755102
                    ]
                ],
                "precision": [
                    0.15704545454545454,
                    [
                        0.07585469027210759,
                        0.2632201304321889
                    ]
                ],
                "recall": [
                    0.3,
                    [
                        0.21562306404154347,
                        0.39
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.2204301242236025,
                    [
                        0.13335570439150085,
                        0.32607880100052733
                    ]
                ],
                "accuracy": [
                    0.20408163265306123,
                    [
                        0.1326530612244898,
                        0.29591836734693877
                    ]
                ],
                "precision": [
                    0.47955448201825013,
                    [
                        0.2811468283105276,
                        0.6869094787751191
                    ]
                ],
                "recall": [
                    0.33,
                    [
                        0.24,
                        0.42424242424242425
                    ]
                ]
            }
        }
    },
    "gpt-4o-2024-08-06": {
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.701376796177581,
                    [
                        0.611246603000987,
                        0.7687977095340444
                    ]
                ],
                "accuracy": [
                    0.5510204081632653,
                    [
                        0.4489795918367347,
                        0.6428571428571429
                    ]
                ],
                "precision": [
                    0.7166612903225805,
                    [
                        0.5984803722490668,
                        0.7791044023784842
                    ]
                ],
                "recall": [
                    0.72,
                    [
                        0.63,
                        0.8
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.711638363187861,
                    [
                        0.6281404410797716,
                        0.7824216739105051
                    ]
                ],
                "accuracy": [
                    0.5408163265306123,
                    [
                        0.4387755102040816,
                        0.6428571428571429
                    ]
                ],
                "precision": [
                    0.7322948717948718,
                    [
                        0.6397000054469953,
                        0.7928415204318182
                    ]
                ],
                "recall": [
                    0.73,
                    [
                        0.6363636363636364,
                        0.8135981296570013
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6953935700406287,
                    [
                        0.6050834267077715,
                        0.764971671103503
                    ]
                ],
                "accuracy": [
                    0.5408163265306123,
                    [
                        0.4387755102040816,
                        0.6428571428571429
                    ]
                ],
                "precision": [
                    0.7302727272727273,
                    [
                        0.6330671720353392,
                        0.7922670240158387
                    ]
                ],
                "recall": [
                    0.71,
                    [
                        0.6199409163924638,
                        0.7977925718377222
                    ]
                ]
            }
        }
    },
    "MeLLaMA-70B-chat": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.5950666666666667,
                    [
                        0.47577423899099786,
                        0.6960646538731534
                    ]
                ],
                "accuracy": [
                    0.6122448979591837,
                    [
                        0.5012936574641425,
                        0.7040816326530612
                    ]
                ],
                "precision": [
                    0.6610738663536369,
                    [
                        0.4366363736894896,
                        0.7681071910821128
                    ]
                ],
                "recall": [
                    0.64,
                    [
                        0.5406808306474339,
                        0.7244897959183674
                    ]
                ]
            }
        }
    },
    "medgemma-27b-text-it": {
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6492935579622329,
                    [
                        0.5611494130365142,
                        0.7314793648917853
                    ]
                ],
                "accuracy": [
                    0.4897959183673469,
                    [
                        0.3979591836734694,
                        0.5918367346938775
                    ]
                ],
                "precision": [
                    0.6503553113553113,
                    [
                        0.5527391576868996,
                        0.7249965178083373
                    ]
                ],
                "recall": [
                    0.67,
                    [
                        0.58,
                        0.7571259709950953
                    ]
                ]
            }
        },
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6517552123086812,
                    [
                        0.5571259827777506,
                        0.7266400021148622
                    ]
                ],
                "accuracy": [
                    0.5,
                    [
                        0.3979591836734694,
                        0.5920918367346937
                    ]
                ],
                "precision": [
                    0.6578791208791209,
                    [
                        0.5634288636072006,
                        0.7340544411743474
                    ]
                ],
                "recall": [
                    0.68,
                    [
                        0.59,
                        0.7622892957774452
                    ]
                ]
            }
        },
        "selected_5shot": {
            "metrics": {
                "f1-weighted": [
                    0.7033842861468912,
                    [
                        0.6274340700301214,
                        0.7755016232038899
                    ]
                ],
                "accuracy": [
                    0.5612244897959183,
                    [
                        0.46938775510204084,
                        0.6632653061224489
                    ]
                ],
                "precision": [
                    0.6890764617691154,
                    [
                        0.6081661329420788,
                        0.7559864102449989
                    ]
                ],
                "recall": [
                    0.73,
                    [
                        0.65,
                        0.81
                    ]
                ]
            }
        }
    },
    "gemma-3-27b-it": {
        "selected_3shot": {
            "metrics": {
                "f1-weighted": [
                    0.6310253935375111,
                    [
                        0.542144518132545,
                        0.7022620768728425
                    ]
                ],
                "accuracy": [
                    0.45918367346938777,
                    [
                        0.35714285714285715,
                        0.5612244897959183
                    ]
                ],
                "precision": [
                    0.635167495245404,
                    [
                        0.5488935397149581,
                        0.7057991608008977
                    ]
                ],
                "recall": [
                    0.68,
                    [
                        0.5858387684758362,
                        0.76
                    ]
                ]
            }
        },
        "selected_1shot": {
            "metrics": {
                "f1-weighted": [
                    0.6373654761904762,
                    [
                        0.5464538573811049,
                        0.7111162736836042
                    ]
                ],
                "accuracy": [
                    0.4387755102040816,
                    [
                        0.336734693877551,
                        0.5408163265306123
                    ]
                ],
                "precision": [
                    0.6593701826628656,
                    [
                        0.5565062851317537,
                        0.7221636833717598
                    ]
                ],
                "recall": [
                    0.67,
                    [
                        0.5709631759540938,
                        0.7575757575757576
                    ]
                ]
            }
        }
    }
}