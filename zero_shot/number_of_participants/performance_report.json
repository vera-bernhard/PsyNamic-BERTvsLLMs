{
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.04411151960784313,
                [
                    0.010008169934640524,
                    0.1194473534010349
                ]
            ],
            "accuracy": [
                0.07291666666666667,
                [
                    0.03125,
                    0.13541666666666666
                ]
            ],
            "precision": [
                0.15503102836879432,
                [
                    0.01340868794326241,
                    0.33873660026988867
                ]
            ],
            "recall": [
                0.08333333333333333,
                [
                    0.041666666666666664,
                    0.14583333333333334
                ]
            ]
        },
        "nr_faulty_parsable": 1,
        "nr_non_parsable": 1
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.38824703788134646,
                [
                    0.293354042896263,
                    0.48460172535044377
                ]
            ],
            "accuracy": [
                0.3645833333333333,
                [
                    0.2708333333333333,
                    0.46875
                ]
            ],
            "precision": [
                0.3664186507936508,
                [
                    0.24550143648577918,
                    0.4596938369596638
                ]
            ],
            "recall": [
                0.4583333333333333,
                [
                    0.3645833333333333,
                    0.5625
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.013095238095238096,
                [
                    0.0,
                    0.07229936805445294
                ]
            ],
            "accuracy": [
                0.010416666666666666,
                [
                    0.0,
                    0.0625
                ]
            ],
            "precision": [
                0.01762820512820513,
                [
                    0.0,
                    0.1150979214748201
                ]
            ],
            "recall": [
                0.010416666666666666,
                [
                    0.0,
                    0.0625
                ]
            ]
        },
        "nr_faulty_parsable": 13,
        "nr_non_parsable": 83
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.3987763801295132,
                [
                    0.2937400708026879,
                    0.5031367324298567
                ]
            ],
            "accuracy": [
                0.3854166666666667,
                [
                    0.2916666666666667,
                    0.4895833333333333
                ]
            ],
            "precision": [
                0.47492521367521373,
                [
                    0.31015668578556105,
                    0.6588123500136182
                ]
            ],
            "recall": [
                0.5104166666666666,
                [
                    0.40625,
                    0.6041666666666666
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.03762037566742944,
                [
                    0.011691757386498811,
                    0.08800694456876208
                ]
            ],
            "accuracy": [
                0.09375,
                [
                    0.041666666666666664,
                    0.16666666666666666
                ]
            ],
            "precision": [
                0.03181423611111111,
                [
                    0.006924478005123098,
                    0.10396142409886028
                ]
            ],
            "recall": [
                0.09375,
                [
                    0.041666666666666664,
                    0.16666666666666666
                ]
            ]
        },
        "nr_faulty_parsable": 56,
        "nr_non_parsable": 6
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.018333333333333333,
                [
                    0.0,
                    0.08864736530608307
                ]
            ],
            "accuracy": [
                0.010416666666666666,
                [
                    0.0,
                    0.0625
                ]
            ],
            "precision": [
                0.07638888888888888,
                [
                    0.0,
                    0.31248079087134784
                ]
            ],
            "recall": [
                0.010416666666666666,
                [
                    0.0,
                    0.0625
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 92
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.4527621136173768,
                [
                    0.3481336890750877,
                    0.5595037442139837
                ]
            ],
            "accuracy": [
                0.46875,
                [
                    0.375,
                    0.5729166666666666
                ]
            ],
            "precision": [
                0.5222477175602175,
                [
                    0.33782788869226776,
                    0.612480216094351
                ]
            ],
            "recall": [
                0.5104166666666666,
                [
                    0.4166666666666667,
                    0.6145833333333334
                ]
            ]
        },
        "nr_faulty_parsable": 47,
        "nr_non_parsable": 0
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.6656159618361703,
                [
                    0.5543703583920792,
                    0.7643221428886371
                ]
            ],
            "accuracy": [
                0.6979166666666666,
                [
                    0.6041666666666666,
                    0.78125
                ]
            ],
            "precision": [
                0.7389364919354838,
                [
                    0.5469058846345065,
                    0.8046150412162499
                ]
            ],
            "recall": [
                0.6979166666666666,
                [
                    0.6041666666666666,
                    0.78125
                ]
            ]
        },
        "nr_faulty_parsable": 5,
        "nr_non_parsable": 0
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.0394808743169399,
                [
                    0.010883084577114427,
                    0.10903316811833932
                ]
            ],
            "accuracy": [
                0.041666666666666664,
                [
                    0.010416666666666666,
                    0.10416666666666667
                ]
            ],
            "precision": [
                0.08674242424242425,
                [
                    0.039419934640522875,
                    0.20056977392737307
                ]
            ],
            "recall": [
                0.052083333333333336,
                [
                    0.020833333333333332,
                    0.11458333333333333
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 34
    },
    "biolinkbert": {
        "metrics": {
            "f1-weighted": [
                0.9188217149565832,
                [
                    0.8484687769929972,
                    0.9606107807260296
                ]
            ],
            "accuracy": [
                0.9166666666666666,
                [
                    0.84375,
                    0.9583333333333334
                ]
            ],
            "precision": [
                0.9425347222222222,
                [
                    0.86458108131056,
                    0.9635416666666666
                ]
            ],
            "recall": [
                0.9166666666666666,
                [
                    0.84375,
                    0.9583333333333334
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}