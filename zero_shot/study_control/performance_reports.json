{
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.18427007178537164,
                [
                    0.1144512942953449,
                    0.26841309893106974
                ]
            ],
            "accuracy": [
                0.061224489795918366,
                [
                    0.02040816326530612,
                    0.12244897959183673
                ]
            ],
            "precision": [
                0.19454545454545452,
                [
                    0.105234051865541,
                    0.30938782864874254
                ]
            ],
            "recall": [
                0.25,
                [
                    0.1717171717171717,
                    0.3431372549019608
                ]
            ]
        }
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.6988205348886463,
                [
                    0.6097195471466711,
                    0.7729544306447315
                ]
            ],
            "accuracy": [
                0.5408163265306123,
                [
                    0.4387755102040816,
                    0.6428571428571429
                ]
            ],
            "precision": [
                0.7164166666666667,
                [
                    0.6127290637910673,
                    0.7834278727951535
                ]
            ],
            "recall": [
                0.71,
                [
                    0.6161616161616161,
                    0.7920792079207921
                ]
            ]
        }
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.6530180582871445,
                [
                    0.572636567625268,
                    0.7156446074558235
                ]
            ],
            "accuracy": [
                0.2653061224489796,
                [
                    0.1836734693877551,
                    0.35714285714285715
                ]
            ],
            "precision": [
                0.6066755741730464,
                [
                    0.5269632012503409,
                    0.6726198015326393
                ]
            ],
            "recall": [
                0.75,
                [
                    0.6565656565656566,
                    0.83
                ]
            ]
        }
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5712686814487493,
                [
                    0.466913950473706,
                    0.6679344976893368
                ]
            ],
            "accuracy": [
                0.5,
                [
                    0.3979591836734694,
                    0.6020408163265306
                ]
            ],
            "precision": [
                0.6935164835164835,
                [
                    0.5829128867083767,
                    0.7744696608940714
                ]
            ],
            "recall": [
                0.59,
                [
                    0.49,
                    0.6836734693877551
                ]
            ]
        }
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6235620185996126,
                [
                    0.5421614087379795,
                    0.6918030372235031
                ]
            ],
            "accuracy": [
                0.2857142857142857,
                [
                    0.20408163265306123,
                    0.37755102040816324
                ]
            ],
            "precision": [
                0.5821314229249012,
                [
                    0.49469935804066645,
                    0.6511168461331586
                ]
            ],
            "recall": [
                0.72,
                [
                    0.6262626262626263,
                    0.801980198019802
                ]
            ]
        }
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.31359213250517604,
                [
                    0.21848618743175438,
                    0.41165184057488285
                ]
            ],
            "accuracy": [
                0.23469387755102042,
                [
                    0.15306122448979592,
                    0.32653061224489793
                ]
            ],
            "precision": [
                0.4645402298850575,
                [
                    0.21135728632530756,
                    0.5668313685231152
                ]
            ],
            "recall": [
                0.37,
                [
                    0.28,
                    0.47
                ]
            ]
        }
    },
    "tuned": {
        "metrics": {
            "f1-weighted": [
                0.7442849608087319,
                [
                    0.651183744961444,
                    0.821255088191789
                ]
            ],
            "accuracy": [
                0.7142857142857143,
                [
                    0.6122448979591837,
                    0.7959183673469388
                ]
            ],
            "precision": [
                0.7357382847038019,
                [
                    0.6277159780514153,
                    0.8061996007920383
                ]
            ],
            "recall": [
                0.76,
                [
                    0.67,
                    0.8383838383838383
                ]
            ]
        }
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.3143904807158067,
                [
                    0.22335401531770352,
                    0.41269670244559176
                ]
            ],
            "accuracy": [
                0.24489795918367346,
                [
                    0.16326530612244897,
                    0.336734693877551
                ]
            ],
            "precision": [
                0.42941415124959426,
                [
                    0.2852499213234003,
                    0.549989448012051
                ]
            ],
            "recall": [
                0.37,
                [
                    0.27722772277227725,
                    0.47
                ]
            ]
        }
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.5836572898013577,
                [
                    0.47659773901521646,
                    0.6812962947826753
                ]
            ],
            "accuracy": [
                0.5612244897959183,
                [
                    0.45918367346938777,
                    0.6552191977855597
                ]
            ],
            "precision": [
                0.5864009324009324,
                [
                    0.4548681348394214,
                    0.6868654074693755
                ]
            ],
            "recall": [
                0.62,
                [
                    0.5204081632653061,
                    0.71
                ]
            ]
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.57932588177196,
                [
                    0.4855309995746204,
                    0.6619294609000627
                ]
            ],
            "accuracy": [
                0.29591836734693877,
                [
                    0.21428571428571427,
                    0.3877551020408163
                ]
            ],
            "precision": [
                0.5976967418546366,
                [
                    0.47937052667966434,
                    0.6861473146118435
                ]
            ],
            "recall": [
                0.65,
                [
                    0.5510204081632653,
                    0.74
                ]
            ]
        }
    },
    "pubmedbert": {
        "metrics": {
            "f1-weighted": [
                0.7462985646235896,
                [
                    0.6539816951959435,
                    0.8263767258943766
                ]
            ],
            "accuracy": [
                0.7448979591836735,
                [
                    0.6530612244897959,
                    0.826530612244898
                ]
            ],
            "precision": [
                0.7729241810820758,
                [
                    0.6610306945436093,
                    0.8414784214434216
                ]
            ],
            "recall": [
                0.75,
                [
                    0.6633663366336634,
                    0.826530612244898
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "medgemma-27b-text-it": {
        "metrics": {
            "f1-weighted": [
                0.6333000325711681,
                [
                    0.5460485416540329,
                    0.7188242838921998
                ]
            ],
            "accuracy": [
                0.47959183673469385,
                [
                    0.37755102040816324,
                    0.5816326530612245
                ]
            ],
            "precision": [
                0.6502923242467719,
                [
                    0.5515841565199648,
                    0.7293389919589376
                ]
            ],
            "recall": [
                0.65,
                [
                    0.5508227443202098,
                    0.7346938775510204
                ]
            ]
        }
    }
}