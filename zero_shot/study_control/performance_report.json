{
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.11238624873609707,
                [
                    0.04998537736249313,
                    0.22049900892096444
                ]
            ],
            "accuracy": [
                0.05102040816326531,
                [
                    0.02040816326530612,
                    0.11224489795918367
                ]
            ],
            "precision": [
                0.43111111111111117,
                [
                    0.21832940647132923,
                    0.7268043303209974
                ]
            ],
            "recall": [
                0.07,
                [
                    0.03,
                    0.14705882352941177
                ]
            ]
        },
        "nr_faulty_parsable": 6,
        "nr_non_parsable": 85
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.18427007178537164,
                [
                    0.1144512942953449,
                    0.26841309893106974
                ]
            ],
            "accuracy": [
                0.061224489795918366,
                [
                    0.02040816326530612,
                    0.12244897959183673
                ]
            ],
            "precision": [
                0.19454545454545452,
                [
                    0.105234051865541,
                    0.30938782864874254
                ]
            ],
            "recall": [
                0.25,
                [
                    0.1717171717171717,
                    0.3431372549019608
                ]
            ]
        },
        "nr_faulty_parsable": 98,
        "nr_non_parsable": 0
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.6988205348886463,
                [
                    0.6097195471466711,
                    0.7729544306447315
                ]
            ],
            "accuracy": [
                0.5408163265306123,
                [
                    0.4387755102040816,
                    0.6428571428571429
                ]
            ],
            "precision": [
                0.7164166666666667,
                [
                    0.6127290637910673,
                    0.7834278727951535
                ]
            ],
            "recall": [
                0.71,
                [
                    0.6161616161616161,
                    0.7920792079207921
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.6530180582871445,
                [
                    0.572636567625268,
                    0.7156446074558235
                ]
            ],
            "accuracy": [
                0.2653061224489796,
                [
                    0.1836734693877551,
                    0.35714285714285715
                ]
            ],
            "precision": [
                0.6066755741730464,
                [
                    0.5269632012503409,
                    0.6726198015326393
                ]
            ],
            "recall": [
                0.75,
                [
                    0.6565656565656566,
                    0.83
                ]
            ]
        },
        "nr_faulty_parsable": 2,
        "nr_non_parsable": 0
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5744489339809477,
                [
                    0.4759933535284872,
                    0.6692412613322595
                ]
            ],
            "accuracy": [
                0.41836734693877553,
                [
                    0.32653061224489793,
                    0.5204081632653061
                ]
            ],
            "precision": [
                0.6863282794990113,
                [
                    0.5815439894086346,
                    0.8194377406925484
                ]
            ],
            "recall": [
                0.59,
                [
                    0.4898866773362848,
                    0.6831683168316832
                ]
            ]
        },
        "nr_faulty_parsable": 2,
        "nr_non_parsable": 0
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6235620185996126,
                [
                    0.5421614087379795,
                    0.6918030372235031
                ]
            ],
            "accuracy": [
                0.2857142857142857,
                [
                    0.20408163265306123,
                    0.37755102040816324
                ]
            ],
            "precision": [
                0.5821314229249012,
                [
                    0.49469935804066645,
                    0.6511168461331586
                ]
            ],
            "recall": [
                0.72,
                [
                    0.6262626262626263,
                    0.801980198019802
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.3143904807158067,
                [
                    0.22335401531770352,
                    0.41269670244559176
                ]
            ],
            "accuracy": [
                0.24489795918367346,
                [
                    0.16326530612244897,
                    0.336734693877551
                ]
            ],
            "precision": [
                0.42941415124959426,
                [
                    0.2852499213234003,
                    0.549989448012051
                ]
            ],
            "recall": [
                0.37,
                [
                    0.27722772277227725,
                    0.47
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.5886130180523773,
                [
                    0.4852333110486391,
                    0.6801830724846682
                ]
            ],
            "accuracy": [
                0.5510204081632653,
                [
                    0.4489795918367347,
                    0.6530612244897959
                ]
            ],
            "precision": [
                0.5719248726655348,
                [
                    0.4532593747633526,
                    0.6676704840547159
                ]
            ],
            "recall": [
                0.62,
                [
                    0.5204081632653061,
                    0.71
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.5660304108987035,
                [
                    0.47127393563854797,
                    0.6512612379226311
                ]
            ],
            "accuracy": [
                0.2857142857142857,
                [
                    0.20408163265306123,
                    0.37755102040816324
                ]
            ],
            "precision": [
                0.5936301343939341,
                [
                    0.46818220887407663,
                    0.685763305074677
                ]
            ],
            "recall": [
                0.63,
                [
                    0.5306122448979592,
                    0.7227722772277227
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 2
    },
    "pubmedbert": {
        "metrics": {
            "f1-weighted": [
                0.7462985646235896,
                [
                    0.6539816951959435,
                    0.8263767258943766
                ]
            ],
            "accuracy": [
                0.7448979591836735,
                [
                    0.6530612244897959,
                    0.826530612244898
                ]
            ],
            "precision": [
                0.7729241810820758,
                [
                    0.6610306945436093,
                    0.8414784214434216
                ]
            ],
            "recall": [
                0.75,
                [
                    0.6633663366336634,
                    0.826530612244898
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}