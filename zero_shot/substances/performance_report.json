{
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.7939223242185498,
                [
                    0.7240344259850456,
                    0.8566353579357612
                ]
            ],
            "accuracy": [
                0.6875,
                [
                    0.59375,
                    0.78125
                ]
            ],
            "precision": [
                0.8370836059701551,
                [
                    0.7514607148105384,
                    0.9010941556255253
                ]
            ],
            "recall": [
                0.7862595419847328,
                [
                    0.7147767212166037,
                    0.8487394957983193
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 4
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.9225763230855201,
                [
                    0.8836324398597137,
                    0.9471869440632263
                ]
            ],
            "accuracy": [
                0.78125,
                [
                    0.6875,
                    0.8541666666666666
                ]
            ],
            "precision": [
                0.895757798007616,
                [
                    0.8459008111882308,
                    0.9262932085987015
                ]
            ],
            "recall": [
                0.9618320610687023,
                [
                    0.920523534959345,
                    0.9855072463768116
                ]
            ]
        },
        "nr_faulty_parsable": 2,
        "nr_non_parsable": 0
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.8488921818773164,
                [
                    0.7744806997671259,
                    0.8985767704293212
                ]
            ],
            "accuracy": [
                0.7083333333333334,
                [
                    0.6145833333333334,
                    0.7916666666666666
                ]
            ],
            "precision": [
                0.829578882716135,
                [
                    0.7509209961945265,
                    0.8757513297023783
                ]
            ],
            "recall": [
                0.9007633587786259,
                [
                    0.8321689197119023,
                    0.946969696969697
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.8455347250847451,
                [
                    0.7738195219804065,
                    0.8933355267225032
                ]
            ],
            "accuracy": [
                0.7083333333333334,
                [
                    0.6041666666666666,
                    0.7916666666666666
                ]
            ],
            "precision": [
                0.8377792065653137,
                [
                    0.7441846914635739,
                    0.8912461634857245
                ]
            ],
            "recall": [
                0.8778625954198473,
                [
                    0.8153846153846154,
                    0.9256198347107438
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.6530918594490174,
                [
                    0.562869749430933,
                    0.7393010880356489
                ]
            ],
            "accuracy": [
                0.5520833333333334,
                [
                    0.4479166666666667,
                    0.6458333333333334
                ]
            ],
            "precision": [
                0.7743479643765904,
                [
                    0.6864726732425083,
                    0.8506227089785696
                ]
            ],
            "recall": [
                0.5877862595419847,
                [
                    0.4820652890818592,
                    0.680327868852459
                ]
            ]
        },
        "nr_faulty_parsable": 14,
        "nr_non_parsable": 13
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.12252742727537708,
                [
                    0.05434258506753622,
                    0.23974846412158046
                ]
            ],
            "accuracy": [
                0.041666666666666664,
                [
                    0.010416666666666666,
                    0.10416666666666667
                ]
            ],
            "precision": [
                0.7061068702290076,
                [
                    0.5514705882352942,
                    0.8728707254746821
                ]
            ],
            "recall": [
                0.06870229007633588,
                [
                    0.02564102564102564,
                    0.14664424242501956
                ]
            ]
        },
        "nr_faulty_parsable": 5,
        "nr_non_parsable": 90
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.7461466698273355,
                [
                    0.6676220588167241,
                    0.8125484730552289
                ]
            ],
            "accuracy": [
                0.5,
                [
                    0.40625,
                    0.6041666666666666
                ]
            ],
            "precision": [
                0.7966914470328681,
                [
                    0.716386691421347,
                    0.9070962156076608
                ]
            ],
            "recall": [
                0.7633587786259542,
                [
                    0.6818181818181818,
                    0.8306451612903226
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 1
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.8717104841132918,
                [
                    0.8104044635088599,
                    0.9081884410121962
                ]
            ],
            "accuracy": [
                0.71875,
                [
                    0.625,
                    0.8020833333333334
                ]
            ],
            "precision": [
                0.8236470210777008,
                [
                    0.7520565388823387,
                    0.8677225143158458
                ]
            ],
            "recall": [
                0.9312977099236641,
                [
                    0.875,
                    0.9682662364024064
                ]
            ]
        },
        "nr_faulty_parsable": 1,
        "nr_non_parsable": 0
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.5242080577990703,
                [
                    0.44886029320284576,
                    0.598140697203932
                ]
            ],
            "accuracy": [
                0.375,
                [
                    0.28125,
                    0.46875
                ]
            ],
            "precision": [
                0.5292311935528169,
                [
                    0.453374366119433,
                    0.6010031268646233
                ]
            ],
            "recall": [
                0.5343511450381679,
                [
                    0.44291936301541834,
                    0.6191505830735297
                ]
            ]
        },
        "nr_faulty_parsable": 96,
        "nr_non_parsable": 0
    },
    "biolinkbert": {
        "metrics": {
            "f1-weighted": [
                0.8714958367665573,
                [
                    0.8027057744023048,
                    0.9201890089297596
                ]
            ],
            "accuracy": [
                0.78125,
                [
                    0.6875,
                    0.8541666666666666
                ]
            ],
            "precision": [
                0.885745803262797,
                [
                    0.8223567726055241,
                    0.9439271278216989
                ]
            ],
            "recall": [
                0.8702290076335878,
                [
                    0.7913669064748201,
                    0.9243697478991596
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}