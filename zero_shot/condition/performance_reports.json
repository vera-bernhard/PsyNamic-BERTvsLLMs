{
    "tuned": {
        "metrics": {
            "f1-weighted": [
                0.9138440394884545,
                [
                    0.849474458511321,
                    0.9498344614929205
                ]
            ],
            "accuracy": [
                0.84375,
                [
                    0.7604166666666666,
                    0.90625
                ]
            ],
            "precision": [
                0.8993464052287582,
                [
                    0.8208803514227028,
                    0.9408388829309658
                ]
            ],
            "recall": [
                0.9352941176470588,
                [
                    0.8651685393258427,
                    0.9715909090909091
                ]
            ]
        }
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.8209436658676644,
                [
                    0.7489260494810213,
                    0.8749653931921215
                ]
            ],
            "accuracy": [
                0.625,
                [
                    0.5208333333333334,
                    0.71875
                ]
            ],
            "precision": [
                0.872328931572629,
                [
                    0.8002096310981687,
                    0.9221481984457446
                ]
            ],
            "recall": [
                0.8176470588235294,
                [
                    0.7461038189048955,
                    0.8735632183908046
                ]
            ]
        }
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.8274849465157718,
                [
                    0.7595508403222919,
                    0.8698338580744603
                ]
            ],
            "accuracy": [
                0.5833333333333334,
                [
                    0.4791666666666667,
                    0.6770833333333334
                ]
            ],
            "precision": [
                0.8235469597489378,
                [
                    0.7378226958322336,
                    0.8692718770501436
                ]
            ],
            "recall": [
                0.8588235294117647,
                [
                    0.8,
                    0.9064327485380117
                ]
            ]
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.7407084529143353,
                [
                    0.6653158246421366,
                    0.7938030056515013
                ]
            ],
            "accuracy": [
                0.34375,
                [
                    0.25,
                    0.4479166666666667
                ]
            ],
            "precision": [
                0.6981953379455573,
                [
                    0.6164839053587151,
                    0.7502270486140646
                ]
            ],
            "recall": [
                0.8705882352941177,
                [
                    0.807909604519774,
                    0.9152542372881356
                ]
            ]
        }
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.7379382846980644,
                [
                    0.6622344737054106,
                    0.7942587446869783
                ]
            ],
            "accuracy": [
                0.4375,
                [
                    0.34375,
                    0.53125
                ]
            ],
            "precision": [
                0.7404741630475322,
                [
                    0.6591552881077091,
                    0.7922716896392697
                ]
            ],
            "recall": [
                0.7941176470588235,
                [
                    0.7125748502994012,
                    0.8588570416608993
                ]
            ]
        }
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.3486505713550569,
                [
                    0.26036051154396284,
                    0.43379463593954976
                ]
            ],
            "accuracy": [
                0.07291666666666667,
                [
                    0.03125,
                    0.13541666666666666
                ]
            ],
            "precision": [
                0.4391795639328072,
                [
                    0.3199621531785286,
                    0.5319603723292372
                ]
            ],
            "recall": [
                0.4588235294117647,
                [
                    0.367816091954023,
                    0.5439560439560439
                ]
            ]
        }
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5980158614314213,
                [
                    0.5177168039086337,
                    0.67669927076535
                ]
            ],
            "accuracy": [
                0.3541666666666667,
                [
                    0.2604166666666667,
                    0.4583333333333333
                ]
            ],
            "precision": [
                0.762169097524067,
                [
                    0.6423260084774743,
                    0.8334477376503863
                ]
            ],
            "recall": [
                0.5294117647058824,
                [
                    0.4444444444444444,
                    0.6149110945593131
                ]
            ]
        }
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6967179925314715,
                [
                    0.6268380073723777,
                    0.7473051950055957
                ]
            ],
            "accuracy": [
                0.28125,
                [
                    0.19791666666666666,
                    0.375
                ]
            ],
            "precision": [
                0.640322275104726,
                [
                    0.5667029325537745,
                    0.6840154100595763
                ]
            ],
            "recall": [
                0.8764705882352941,
                [
                    0.8136645962732919,
                    0.9202453987730062
                ]
            ]
        }
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.6591079409273868,
                [
                    0.5650982520166338,
                    0.7301208773402144
                ]
            ],
            "accuracy": [
                0.4166666666666667,
                [
                    0.3229166666666667,
                    0.5104166666666666
                ]
            ],
            "precision": [
                0.7552250650780062,
                [
                    0.68655367514569,
                    0.7965457236182741
                ]
            ],
            "recall": [
                0.7235294117647059,
                [
                    0.6414095316654119,
                    0.7916929634535798
                ]
            ]
        }
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.7315780101716083,
                [
                    0.6638640551630398,
                    0.7850219617564064
                ]
            ],
            "accuracy": [
                0.2916666666666667,
                [
                    0.20833333333333334,
                    0.3854166666666667
                ]
            ],
            "precision": [
                0.7160505555225948,
                [
                    0.6441322903966598,
                    0.7734621055437245
                ]
            ],
            "recall": [
                0.8235294117647058,
                [
                    0.7583115464306699,
                    0.8757763975155279
                ]
            ]
        }
    },
    "biomedbert-abstract": {
        "metrics": {
            "f1-weighted": [
                0.929756369391258,
                [
                    0.8683545508135674,
                    0.965182105975902
                ]
            ],
            "accuracy": [
                0.8645833333333334,
                [
                    0.78125,
                    0.9270833333333334
                ]
            ],
            "precision": [
                0.9466124271005832,
                [
                    0.886104581241186,
                    0.9770821491382768
                ]
            ],
            "recall": [
                0.9176470588235294,
                [
                    0.842391304347826,
                    0.9620253164556962
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "medgemma-27b-text-it": {
        "metrics": {
            "f1-weighted": [
                0.8278490817505074,
                [
                    0.7636426064262632,
                    0.8766807452225934
                ]
            ],
            "accuracy": [
                0.625,
                [
                    0.5216628121536058,
                    0.7083333333333334
                ]
            ],
            "precision": [
                0.8202086606730571,
                [
                    0.7469747740040895,
                    0.8684180615993253
                ]
            ],
            "recall": [
                0.8705882352941177,
                [
                    0.8177764528373338,
                    0.9129922541659998
                ]
            ]
        }
    },
    "gemma-3-27b-it": {
        "metrics": {
            "f1-weighted": [
                0.7656853434455655,
                [
                    0.7035529702116607,
                    0.8120604049040258
                ]
            ],
            "accuracy": [
                0.4270833333333333,
                [
                    0.3333333333333333,
                    0.53125
                ]
            ],
            "precision": [
                0.7252346552656149,
                [
                    0.65710569790765,
                    0.7674752889108953
                ]
            ],
            "recall": [
                0.888235294117647,
                [
                    0.8362573099415205,
                    0.9298245614035088
                ]
            ]
        }
    }
}