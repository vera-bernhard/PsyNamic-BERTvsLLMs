{
    "tuned": {
        "metrics": {
            "f1-weighted": [
                0.8784962525460559,
                [
                    0.8010762293817372,
                    0.9352156128193236
                ]
            ],
            "accuracy": [
                0.865979381443299,
                [
                    0.7938144329896907,
                    0.9278350515463918
                ]
            ],
            "precision": [
                0.8987297106563161,
                [
                    0.8068645268788586,
                    0.9493846575599805
                ]
            ],
            "recall": [
                0.8715596330275229,
                [
                    0.7981651376146789,
                    0.9259259259259259
                ]
            ]
        }
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.34715472991555774,
                [
                    0.25059964080000474,
                    0.4493784409441123
                ]
            ],
            "accuracy": [
                0.26804123711340205,
                [
                    0.18556701030927836,
                    0.36082474226804123
                ]
            ],
            "precision": [
                0.6239298552190874,
                [
                    0.43443055098514266,
                    0.7340275612870729
                ]
            ],
            "recall": [
                0.3669724770642202,
                [
                    0.28703703703703703,
                    0.4519230769230769
                ]
            ]
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.22685105966008393,
                [
                    0.14576288599833573,
                    0.3151301205424437
                ]
            ],
            "accuracy": [
                0.1958762886597938,
                [
                    0.12371134020618557,
                    0.28865979381443296
                ]
            ],
            "precision": [
                0.19256093480106848,
                [
                    0.11179302830124858,
                    0.2780701864333909
                ]
            ],
            "recall": [
                0.3119266055045872,
                [
                    0.22641509433962265,
                    0.40350877192982454
                ]
            ]
        }
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.20266200669870396,
                [
                    0.12492334642775398,
                    0.2915878386686854
                ]
            ],
            "accuracy": [
                0.21649484536082475,
                [
                    0.14432989690721648,
                    0.30927835051546393
                ]
            ],
            "precision": [
                0.15073265582364698,
                [
                    0.08481468758417171,
                    0.23178521136938468
                ]
            ],
            "recall": [
                0.3394495412844037,
                [
                    0.2523364485981308,
                    0.43243243243243246
                ]
            ]
        }
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.2925478011768314,
                [
                    0.20533533554211422,
                    0.39139002266465994
                ]
            ],
            "accuracy": [
                0.23711340206185566,
                [
                    0.15463917525773196,
                    0.32989690721649484
                ]
            ],
            "precision": [
                0.6319133202987919,
                [
                    0.39581796243802625,
                    0.8209268205579316
                ]
            ],
            "recall": [
                0.28440366972477066,
                [
                    0.20952380952380953,
                    0.36607142857142855
                ]
            ]
        }
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.0779816513761468,
                [
                    0.035112462309410196,
                    0.1479321404527099
                ]
            ],
            "accuracy": [
                0.061855670103092786,
                [
                    0.020618556701030927,
                    0.12371134020618557
                ]
            ],
            "precision": [
                0.06442405708460754,
                [
                    0.02482635939907004,
                    0.1382138630741125
                ]
            ],
            "recall": [
                0.1651376146788991,
                [
                    0.10146510446961285,
                    0.24347826086956523
                ]
            ]
        }
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.7791731430660456,
                [
                    0.6943693738234048,
                    0.8466364613229956
                ]
            ],
            "accuracy": [
                0.7319587628865979,
                [
                    0.6391752577319587,
                    0.8144329896907216
                ]
            ],
            "precision": [
                0.8355376188502258,
                [
                    0.7491426373363578,
                    0.8778059049048276
                ]
            ],
            "recall": [
                0.7614678899082569,
                [
                    0.6727272727272727,
                    0.8349514563106796
                ]
            ]
        }
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.14115684639160084,
                [
                    0.07852044676451403,
                    0.2210609207755046
                ]
            ],
            "accuracy": [
                0.14432989690721648,
                [
                    0.08247422680412371,
                    0.2268041237113402
                ]
            ],
            "precision": [
                0.10240138671627277,
                [
                    0.05141436675145017,
                    0.17673244553973097
                ]
            ],
            "recall": [
                0.23853211009174313,
                [
                    0.16981132075471697,
                    0.3157894736842105
                ]
            ]
        }
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.1912391076943097,
                [
                    0.11627942360743893,
                    0.2844157644916598
                ]
            ],
            "accuracy": [
                0.2268041237113402,
                [
                    0.14432989690721648,
                    0.31958762886597936
                ]
            ],
            "precision": [
                0.1591807727096524,
                [
                    0.08651188784673117,
                    0.23864938486591578
                ]
            ],
            "recall": [
                0.3119266055045872,
                [
                    0.22857142857142856,
                    0.4067855828419398
                ]
            ]
        }
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.11762433606953163,
                [
                    0.06401454766575386,
                    0.193919333190139
                ]
            ],
            "accuracy": [
                0.12371134020618557,
                [
                    0.07216494845360824,
                    0.20618556701030927
                ]
            ],
            "precision": [
                0.12522935779816513,
                [
                    0.04421052631578947,
                    0.22486146778219357
                ]
            ],
            "recall": [
                0.22018348623853212,
                [
                    0.1559633027522936,
                    0.29245283018867924
                ]
            ]
        }
    },
    "biomedbert-abstract": {
        "metrics": {
            "f1-weighted": [
                0.8581893179716946,
                [
                    0.7749515574677688,
                    0.9157141794236064
                ]
            ],
            "accuracy": [
                0.8247422680412371,
                [
                    0.7422680412371134,
                    0.8865979381443299
                ]
            ],
            "precision": [
                0.8540578687367677,
                [
                    0.7625744016974515,
                    0.9105233693503466
                ]
            ],
            "recall": [
                0.8623853211009175,
                [
                    0.7787610619469026,
                    0.923809523809524
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "medgemma-27b-text-it": {
        "metrics": {
            "f1-weighted": [
                0.6412531581321107,
                [
                    0.5473052724733294,
                    0.7301592086541718
                ]
            ],
            "accuracy": [
                0.5773195876288659,
                [
                    0.4742268041237113,
                    0.6701030927835051
                ]
            ],
            "precision": [
                0.7675740876990145,
                [
                    0.659145472918139,
                    0.8308144770209093
                ]
            ],
            "recall": [
                0.6238532110091743,
                [
                    0.535201914339854,
                    0.709122082297118
                ]
            ]
        }
    }
}