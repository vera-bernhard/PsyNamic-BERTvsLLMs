{
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6929492154034065,
                [
                    0.6540260357283104,
                    0.7298402630210499
                ]
            ],
            "accuracy": [
                0.6814159292035398,
                [
                    0.6424778761061947,
                    0.7185840707964601
                ]
            ],
            "precision": [
                0.7107672716964752,
                [
                    0.6712994075677101,
                    0.7466159747333423
                ]
            ],
            "recall": [
                0.6920353982300885,
                [
                    0.6530973451327433,
                    0.7292035398230089
                ]
            ]
        }
    },
    "tuned": {
        "metrics": {
            "f1-weighted": [
                0.8805118627008228,
                [
                    0.8521725368648123,
                    0.9052784432765522
                ]
            ],
            "accuracy": [
                0.879646017699115,
                [
                    0.8513274336283185,
                    0.904424778761062
                ]
            ],
            "precision": [
                0.8885188705499921,
                [
                    0.8616993490789865,
                    0.9109488462156448
                ]
            ],
            "recall": [
                0.879646017699115,
                [
                    0.8513274336283185,
                    0.904424778761062
                ]
            ]
        }
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.6018951529994239,
                [
                    0.5560047353966621,
                    0.6462701729343009
                ]
            ],
            "accuracy": [
                0.6176991150442478,
                [
                    0.5769911504424778,
                    0.6566371681415929
                ]
            ],
            "precision": [
                0.6466984113732318,
                [
                    0.5990708949352326,
                    0.6903780958590982
                ]
            ],
            "recall": [
                0.6176991150442478,
                [
                    0.5769911504424778,
                    0.6566371681415929
                ]
            ]
        }
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.3837980916596629,
                [
                    0.3411498562358973,
                    0.4277515628618994
                ]
            ],
            "accuracy": [
                0.36106194690265486,
                [
                    0.32212389380530976,
                    0.40176991150442476
                ]
            ],
            "precision": [
                0.6270446616507318,
                [
                    0.5600145893428012,
                    0.6813795672376389
                ]
            ],
            "recall": [
                0.44424778761061945,
                [
                    0.40530973451327434,
                    0.4849557522123894
                ]
            ]
        }
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.6116427677375437,
                [
                    0.5646982611337015,
                    0.6599042796961162
                ]
            ],
            "accuracy": [
                0.6637168141592921,
                [
                    0.6247787610619469,
                    0.7026548672566372
                ]
            ],
            "precision": [
                0.7014190584905272,
                [
                    0.6526698885922386,
                    0.7425626990243684
                ]
            ],
            "recall": [
                0.6637168141592921,
                [
                    0.6247787610619469,
                    0.7026548672566372
                ]
            ]
        }
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.7156068932205397,
                [
                    0.6756902137788637,
                    0.7513909748223728
                ]
            ],
            "accuracy": [
                0.7132743362831858,
                [
                    0.672566371681416,
                    0.7486725663716814
                ]
            ],
            "precision": [
                0.7206148064059047,
                [
                    0.679777594657298,
                    0.7557573071810809
                ]
            ],
            "recall": [
                0.7132743362831858,
                [
                    0.672566371681416,
                    0.7486725663716814
                ]
            ]
        }
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.4905339573667968,
                [
                    0.43955862106678767,
                    0.5420857556183345
                ]
            ],
            "accuracy": [
                0.6017699115044248,
                [
                    0.5610619469026549,
                    0.6407079646017699
                ]
            ],
            "precision": [
                0.7215011688278772,
                [
                    0.6063584778647281,
                    0.7703220187408907
                ]
            ],
            "recall": [
                0.6017699115044248,
                [
                    0.5610619469026549,
                    0.6407079646017699
                ]
            ]
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6651716881805377,
                [
                    0.6264058080914133,
                    0.7016424511752677
                ]
            ],
            "accuracy": [
                0.6407079646017699,
                [
                    0.6,
                    0.679646017699115
                ]
            ],
            "precision": [
                0.6813287385509819,
                [
                    0.641128469575656,
                    0.7172052748888802
                ]
            ],
            "recall": [
                0.6743362831858407,
                [
                    0.6353982300884956,
                    0.7115044247787611
                ]
            ]
        }
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.7467454165294943,
                [
                    0.7097253539545411,
                    0.7815324178608667
                ]
            ],
            "accuracy": [
                0.7451327433628319,
                [
                    0.7079646017699115,
                    0.7805309734513274
                ]
            ],
            "precision": [
                0.7520069882773254,
                [
                    0.7140271800012397,
                    0.7859735452093324
                ]
            ],
            "recall": [
                0.7451327433628319,
                [
                    0.7079646017699115,
                    0.7805309734513274
                ]
            ]
        }
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.7663950589473554,
                [
                    0.7316068035849045,
                    0.7993166797238859
                ]
            ],
            "accuracy": [
                0.7646017699115044,
                [
                    0.7292035398230089,
                    0.7982300884955752
                ]
            ],
            "precision": [
                0.777017067606075,
                [
                    0.7423112259072283,
                    0.8084802944866931
                ]
            ],
            "recall": [
                0.7646017699115044,
                [
                    0.7292035398230089,
                    0.7982300884955752
                ]
            ]
        }
    },
    "biobert": {
        "metrics": {
            "f1-weighted": [
                0.906486212187604,
                [
                    0.8800689576185433,
                    0.9291715423395434
                ]
            ],
            "accuracy": [
                0.9061946902654868,
                [
                    0.879646017699115,
                    0.927433628318584
                ]
            ],
            "precision": [
                0.9074743305886644,
                [
                    0.8808982778187103,
                    0.928753369937492
                ]
            ],
            "recall": [
                0.9061946902654868,
                [
                    0.879646017699115,
                    0.927433628318584
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}