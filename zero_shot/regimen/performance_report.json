{
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.10313531353135313,
                [
                    0.045226171227255384,
                    0.19844037635432035
                ]
            ],
            "accuracy": [
                0.052083333333333336,
                [
                    0.020833333333333332,
                    0.11458333333333333
                ]
            ],
            "precision": [
                0.49504950495049505,
                [
                    0.17134322818337305,
                    0.6903769462234991
                ]
            ],
            "recall": [
                0.0594059405940594,
                [
                    0.02040816326530612,
                    0.12
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 87
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.4504950495049505,
                [
                    0.3406451004672821,
                    0.5610976269234541
                ]
            ],
            "accuracy": [
                0.46875,
                [
                    0.3645833333333333,
                    0.5625
                ]
            ],
            "precision": [
                0.6602545968882603,
                [
                    0.4274154990034417,
                    0.7493727186787578
                ]
            ],
            "recall": [
                0.49504950495049505,
                [
                    0.4,
                    0.5858585858585859
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.6592763671971593,
                [
                    0.5636314122211231,
                    0.7467735982609788
                ]
            ],
            "accuracy": [
                0.625,
                [
                    0.5208333333333334,
                    0.71875
                ]
            ],
            "precision": [
                0.6811538296686812,
                [
                    0.574230607426002,
                    0.7566994114760033
                ]
            ],
            "recall": [
                0.6633663366336634,
                [
                    0.5686274509803921,
                    0.7475728155339806
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.4410320636241744,
                [
                    0.33286162135041913,
                    0.5497702277337425
                ]
            ],
            "accuracy": [
                0.4375,
                [
                    0.34375,
                    0.53125
                ]
            ],
            "precision": [
                0.7735423542354236,
                [
                    0.4487957957932017,
                    0.815577348860661
                ]
            ],
            "recall": [
                0.48514851485148514,
                [
                    0.39215686274509803,
                    0.5757575757575758
                ]
            ]
        },
        "nr_faulty_parsable": 7,
        "nr_non_parsable": 1
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.733620730494102,
                [
                    0.6432334438859817,
                    0.8127293947228643
                ]
            ],
            "accuracy": [
                0.7083333333333334,
                [
                    0.6145833333333334,
                    0.7916666666666666
                ]
            ],
            "precision": [
                0.7782792421484412,
                [
                    0.68986505971988,
                    0.835857530478075
                ]
            ],
            "recall": [
                0.7227722772277227,
                [
                    0.6336633663366337,
                    0.801980198019802
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6939972511840043,
                [
                    0.5973780274913714,
                    0.7801941424267699
                ]
            ],
            "accuracy": [
                0.6666666666666666,
                [
                    0.5625,
                    0.75
                ]
            ],
            "precision": [
                0.7241181759371951,
                [
                    0.616330613495307,
                    0.801954738559757
                ]
            ],
            "recall": [
                0.6831683168316832,
                [
                    0.5882068949045745,
                    0.7669902912621359
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.27874307364291245,
                [
                    0.19751559975487895,
                    0.37530986655101467
                ]
            ],
            "accuracy": [
                0.041666666666666664,
                [
                    0.010416666666666666,
                    0.10416666666666667
                ]
            ],
            "precision": [
                0.3476127612761276,
                [
                    0.22447272953251132,
                    0.48511361748361875
                ]
            ],
            "recall": [
                0.27722772277227725,
                [
                    0.2,
                    0.36893203883495146
                ]
            ]
        },
        "nr_faulty_parsable": 95,
        "nr_non_parsable": 1
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.30935162017883194,
                [
                    0.21417048033717048,
                    0.4176869899823525
                ]
            ],
            "accuracy": [
                0.375,
                [
                    0.28125,
                    0.4791666666666667
                ]
            ],
            "precision": [
                0.7009837420339144,
                [
                    0.3739729796635577,
                    0.8457173594234682
                ]
            ],
            "recall": [
                0.4158415841584158,
                [
                    0.32673267326732675,
                    0.5097830242430417
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6451494835018092,
                [
                    0.5422876464429178,
                    0.7304813125949373
                ]
            ],
            "accuracy": [
                0.59375,
                [
                    0.4895833333333333,
                    0.6875
                ]
            ],
            "precision": [
                0.7071438820900723,
                [
                    0.5922722562778402,
                    0.7801665816921317
                ]
            ],
            "recall": [
                0.6336633663366337,
                [
                    0.5384615384615384,
                    0.7171717171717171
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "biomedbert-abstract": {
        "metrics": {
            "f1-weighted": [
                0.7348226029371681,
                [
                    0.6363317282311126,
                    0.8104509312162722
                ]
            ],
            "accuracy": [
                0.6979166666666666,
                [
                    0.6041666666666666,
                    0.78125
                ]
            ],
            "precision": [
                0.7120237496958095,
                [
                    0.6085663068609319,
                    0.786335643669799
                ]
            ],
            "recall": [
                0.7623762376237624,
                [
                    0.660377358490566,
                    0.8415841584158416
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}