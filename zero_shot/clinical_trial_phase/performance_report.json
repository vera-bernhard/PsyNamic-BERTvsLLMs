{
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.7054019840050908,
                [
                    0.6709710283985633,
                    0.738557748159583
                ]
            ],
            "accuracy": [
                0.15625,
                [
                    0.09375,
                    0.23958333333333334
                ]
            ],
            "precision": [
                0.5809545354515138,
                [
                    0.538129382175896,
                    0.6431370583672
                ]
            ],
            "recall": [
                0.9484536082474226,
                [
                    0.8877551020408163,
                    0.979381443298969
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 2
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.5337881779545767,
                [
                    0.4325415660332769,
                    0.6214280117551144
                ]
            ],
            "accuracy": [
                0.23958333333333334,
                [
                    0.16666666666666666,
                    0.3333333333333333
                ]
            ],
            "precision": [
                0.5493307581422735,
                [
                    0.4359360839327169,
                    0.6352990102516654
                ]
            ],
            "recall": [
                0.5567010309278351,
                [
                    0.4583333333333333,
                    0.6530612244897959
                ]
            ]
        },
        "nr_faulty_parsable": 14,
        "nr_non_parsable": 0
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.692121044474943,
                [
                    0.5775670221357727,
                    0.7814632483367051
                ]
            ],
            "accuracy": [
                0.6875,
                [
                    0.59375,
                    0.78125
                ]
            ],
            "precision": [
                0.8077565046637211,
                [
                    0.6723822100965016,
                    0.8741496598639454
                ]
            ],
            "recall": [
                0.6907216494845361,
                [
                    0.5959595959595959,
                    0.78125
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.19441674975074774,
                [
                    0.11019937971027675,
                    0.3035043364609466
                ]
            ],
            "accuracy": [
                0.10416666666666667,
                [
                    0.052083333333333336,
                    0.17708333333333334
                ]
            ],
            "precision": [
                0.7270495827196858,
                [
                    0.6047799900550183,
                    0.8217891861529151
                ]
            ],
            "recall": [
                0.13402061855670103,
                [
                    0.07291666666666667,
                    0.21428571428571427
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 56
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.35191679420909255,
                [
                    0.25604270740447355,
                    0.44837146274918027
                ]
            ],
            "accuracy": [
                0.28125,
                [
                    0.19791666666666666,
                    0.375
                ]
            ],
            "precision": [
                0.49613548468297425,
                [
                    0.353954435218113,
                    0.6186659651683079
                ]
            ],
            "recall": [
                0.30927835051546393,
                [
                    0.2268041237113402,
                    0.40625
                ]
            ]
        },
        "nr_faulty_parsable": 94,
        "nr_non_parsable": 2
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.23746491435166972,
                [
                    0.1531778774437608,
                    0.34226639124568375
                ]
            ],
            "accuracy": [
                0.375,
                [
                    0.28125,
                    0.46875
                ]
            ],
            "precision": [
                0.17763398406083206,
                [
                    0.10884502923976609,
                    0.27320215155911143
                ]
            ],
            "recall": [
                0.4020618556701031,
                [
                    0.30927835051546393,
                    0.5
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 1
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.5065840339945554,
                [
                    0.41212072720284004,
                    0.5916338085545827
                ]
            ],
            "accuracy": [
                0.34375,
                [
                    0.25,
                    0.4479166666666667
                ]
            ],
            "precision": [
                0.6670512191130749,
                [
                    0.5630935917203561,
                    0.7307732808626641
                ]
            ],
            "recall": [
                0.4536082474226804,
                [
                    0.3541666666666667,
                    0.5520833333333334
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.22103372315215097,
                [
                    0.13507862483711405,
                    0.3164029302893087
                ]
            ],
            "accuracy": [
                0.19791666666666666,
                [
                    0.125,
                    0.28125
                ]
            ],
            "precision": [
                0.6542310996563574,
                [
                    0.5237912704502663,
                    0.7047609847165882
                ]
            ],
            "recall": [
                0.24742268041237114,
                [
                    0.16494845360824742,
                    0.3402061855670103
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.42407441816685415,
                [
                    0.33386611538464395,
                    0.5065858799973806
                ]
            ],
            "accuracy": [
                0.16666666666666666,
                [
                    0.10416666666666667,
                    0.25
                ]
            ],
            "precision": [
                0.6033986631924776,
                [
                    0.5011396134789327,
                    0.6767794429887156
                ]
            ],
            "recall": [
                0.38144329896907214,
                [
                    0.28865979381443296,
                    0.4791666666666667
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 1
    },
    "clinicalbert": {
        "metrics": {
            "f1-weighted": [
                0.7933675283124271,
                [
                    0.6949074223488295,
                    0.8700759627817463
                ]
            ],
            "accuracy": [
                0.8125,
                [
                    0.7291666666666666,
                    0.8854166666666666
                ]
            ],
            "precision": [
                0.7790005139522931,
                [
                    0.6605584005944638,
                    0.8602349808890631
                ]
            ],
            "recall": [
                0.8144329896907216,
                [
                    0.7310142090524531,
                    0.8854166666666666
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}