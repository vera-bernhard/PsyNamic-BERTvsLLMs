{
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.5337881779545767,
                [
                    0.4325415660332769,
                    0.6214280117551144
                ]
            ],
            "accuracy": [
                0.23958333333333334,
                [
                    0.16666666666666666,
                    0.3333333333333333
                ]
            ],
            "precision": [
                0.5493307581422735,
                [
                    0.4359360839327169,
                    0.6352990102516654
                ]
            ],
            "recall": [
                0.5567010309278351,
                [
                    0.4583333333333333,
                    0.6530612244897959
                ]
            ]
        }
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5435810765026367,
                [
                    0.4234742367971784,
                    0.6507547126483827
                ]
            ],
            "accuracy": [
                0.5833333333333334,
                [
                    0.4791666666666667,
                    0.6770833333333334
                ]
            ],
            "precision": [
                0.6904184354154033,
                [
                    0.35171673320522817,
                    0.7693338639868976
                ]
            ],
            "recall": [
                0.6391752577319587,
                [
                    0.5416666666666666,
                    0.7291666666666666
                ]
            ]
        }
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.2444214719987916,
                [
                    0.15400133995653156,
                    0.34014146166146525
                ]
            ],
            "accuracy": [
                0.19791666666666666,
                [
                    0.125,
                    0.28125
                ]
            ],
            "precision": [
                0.6623332750888229,
                [
                    0.5871335250440183,
                    0.7101043013143185
                ]
            ],
            "recall": [
                0.25773195876288657,
                [
                    0.17346938775510204,
                    0.35051546391752575
                ]
            ]
        }
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.692121044474943,
                [
                    0.5775670221357727,
                    0.7814632483367051
                ]
            ],
            "accuracy": [
                0.6875,
                [
                    0.59375,
                    0.78125
                ]
            ],
            "precision": [
                0.8077565046637211,
                [
                    0.6723822100965016,
                    0.8741496598639454
                ]
            ],
            "recall": [
                0.6907216494845361,
                [
                    0.5959595959595959,
                    0.78125
                ]
            ]
        }
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.35191679420909255,
                [
                    0.25604270740447355,
                    0.44837146274918027
                ]
            ],
            "accuracy": [
                0.28125,
                [
                    0.19791666666666666,
                    0.375
                ]
            ],
            "precision": [
                0.49613548468297425,
                [
                    0.353954435218113,
                    0.6186659651683079
                ]
            ],
            "recall": [
                0.30927835051546393,
                [
                    0.2268041237113402,
                    0.40625
                ]
            ]
        }
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.23746491435166972,
                [
                    0.1531778774437608,
                    0.34226639124568375
                ]
            ],
            "accuracy": [
                0.375,
                [
                    0.28125,
                    0.46875
                ]
            ],
            "precision": [
                0.17763398406083206,
                [
                    0.10884502923976609,
                    0.27320215155911143
                ]
            ],
            "recall": [
                0.4020618556701031,
                [
                    0.30927835051546393,
                    0.5
                ]
            ]
        }
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.5065840339945554,
                [
                    0.41212072720284004,
                    0.5916338085545827
                ]
            ],
            "accuracy": [
                0.34375,
                [
                    0.25,
                    0.4479166666666667
                ]
            ],
            "precision": [
                0.6670512191130749,
                [
                    0.5630935917203561,
                    0.7307732808626641
                ]
            ],
            "recall": [
                0.4536082474226804,
                [
                    0.3541666666666667,
                    0.5520833333333334
                ]
            ]
        }
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.3309921062376818,
                [
                    0.2319978893115061,
                    0.43404406468052303
                ]
            ],
            "accuracy": [
                0.23958333333333334,
                [
                    0.15625,
                    0.3333333333333333
                ]
            ],
            "precision": [
                0.5134086624340458,
                [
                    0.34158620245649474,
                    0.6380279058746684
                ]
            ],
            "recall": [
                0.30927835051546393,
                [
                    0.2204336963041092,
                    0.40625
                ]
            ]
        }
    },
    "tuned": {
        "metrics": {
            "f1-weighted": [
                0.7776791827022141,
                [
                    0.6903564612042151,
                    0.8533237606542439
                ]
            ],
            "accuracy": [
                0.7708333333333334,
                [
                    0.6770833333333334,
                    0.84375
                ]
            ],
            "precision": [
                0.8207903780068729,
                [
                    0.7344822814894,
                    0.8785296746751796
                ]
            ],
            "recall": [
                0.7731958762886598,
                [
                    0.6836734693877551,
                    0.845360824742268
                ]
            ]
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.4231220004415881,
                [
                    0.3328438035206765,
                    0.5058114512755605
                ]
            ],
            "accuracy": [
                0.16666666666666666,
                [
                    0.10416666666666667,
                    0.25
                ]
            ],
            "precision": [
                0.6020146163892517,
                [
                    0.4989258643565621,
                    0.6756959757820451
                ]
            ],
            "recall": [
                0.38144329896907214,
                [
                    0.28865979381443296,
                    0.4791666666666667
                ]
            ]
        }
    },
    "clinicalbert": {
        "metrics": {
            "f1-weighted": [
                0.7933675283124271,
                [
                    0.6949074223488295,
                    0.8700759627817463
                ]
            ],
            "accuracy": [
                0.8125,
                [
                    0.7291666666666666,
                    0.8854166666666666
                ]
            ],
            "precision": [
                0.7790005139522931,
                [
                    0.6605584005944638,
                    0.8602349808890631
                ]
            ],
            "recall": [
                0.8144329896907216,
                [
                    0.7310142090524531,
                    0.8854166666666666
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "medgemma-27b-text-it": {
        "metrics": {
            "f1-weighted": [
                0.5852912842552983,
                [
                    0.4851366182677248,
                    0.6683794827769173
                ]
            ],
            "accuracy": [
                0.53125,
                [
                    0.4270833333333333,
                    0.625
                ]
            ],
            "precision": [
                0.686185251982705,
                [
                    0.5678118268403146,
                    0.7678202863659465
                ]
            ],
            "recall": [
                0.5463917525773195,
                [
                    0.4479166666666667,
                    0.6354166666666666
                ]
            ]
        }
    }
}