{
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.40897018241624433,
                [
                    0.302996937818653,
                    0.5214306532182081
                ]
            ],
            "accuracy": [
                0.29591836734693877,
                [
                    0.21428571428571427,
                    0.3979591836734694
                ]
            ],
            "precision": [
                0.7712261094914156,
                [
                    0.5927408147423017,
                    0.8683708987170005
                ]
            ],
            "recall": [
                0.30612244897959184,
                [
                    0.22448979591836735,
                    0.40816326530612246
                ]
            ]
        }
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.13323283858998144,
                [
                    0.06847343760779398,
                    0.21582390601275792
                ]
            ],
            "accuracy": [
                0.21428571428571427,
                [
                    0.14285714285714285,
                    0.30612244897959184
                ]
            ],
            "precision": [
                0.10058309037900875,
                [
                    0.046837824872006724,
                    0.17858450860779973
                ]
            ],
            "recall": [
                0.21428571428571427,
                [
                    0.14285714285714285,
                    0.30612244897959184
                ]
            ]
        }
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.5498621070049641,
                [
                    0.44510834079133177,
                    0.6462168741573434
                ]
            ],
            "accuracy": [
                0.47959183673469385,
                [
                    0.37755102040816324,
                    0.5816326530612245
                ]
            ],
            "precision": [
                0.772028662581658,
                [
                    0.6658163265306123,
                    0.8334166384874361
                ]
            ],
            "recall": [
                0.5204081632653061,
                [
                    0.41836734693877553,
                    0.6122448979591837
                ]
            ]
        }
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.20279397473275024,
                [
                    0.11589792301639022,
                    0.30882980228298285
                ]
            ],
            "accuracy": [
                0.23469387755102042,
                [
                    0.15306122448979592,
                    0.32653061224489793
                ]
            ],
            "precision": [
                0.8173469387755101,
                [
                    0.08984560105608536,
                    0.866980894174645
                ]
            ],
            "recall": [
                0.24489795918367346,
                [
                    0.16326530612244897,
                    0.336734693877551
                ]
            ]
        }
    },
    "tuned": {
        "metrics": {
            "f1-weighted": [
                0.7829022080128485,
                [
                    0.6820673345959517,
                    0.8604095441343237
                ]
            ],
            "accuracy": [
                0.8061224489795918,
                [
                    0.7142857142857143,
                    0.8775510204081632
                ]
            ],
            "precision": [
                0.7632167152575315,
                [
                    0.6435451551669801,
                    0.848922902494331
                ]
            ],
            "recall": [
                0.8061224489795918,
                [
                    0.7142857142857143,
                    0.8775510204081632
                ]
            ]
        }
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.581275593889825,
                [
                    0.48084937757696905,
                    0.6777919054455778
                ]
            ],
            "accuracy": [
                0.5408163265306123,
                [
                    0.4387755102040816,
                    0.6428571428571429
                ]
            ],
            "precision": [
                0.6501874219075385,
                [
                    0.5161408687612993,
                    0.7553305758494395
                ]
            ],
            "recall": [
                0.5612244897959183,
                [
                    0.45918367346938777,
                    0.6632653061224489
                ]
            ]
        }
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5639957622393219,
                [
                    0.45960933610941324,
                    0.6623673058407927
                ]
            ],
            "accuracy": [
                0.5102040816326531,
                [
                    0.40816326530612246,
                    0.6122448979591837
                ]
            ],
            "precision": [
                0.791663789359642,
                [
                    0.6808032677354572,
                    0.8530303613187111
                ]
            ],
            "recall": [
                0.5102040816326531,
                [
                    0.40816326530612246,
                    0.6122448979591837
                ]
            ]
        }
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.7258268824771288,
                [
                    0.6299280046596621,
                    0.8084891648888267
                ]
            ],
            "accuracy": [
                0.7040816326530612,
                [
                    0.6122448979591837,
                    0.7857142857142857
                ]
            ],
            "precision": [
                0.7936174469787914,
                [
                    0.6791918193340145,
                    0.8657408771516117
                ]
            ],
            "recall": [
                0.7040816326530612,
                [
                    0.6122448979591836,
                    0.7857142857142857
                ]
            ]
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6118646216250476,
                [
                    0.5143547016929918,
                    0.7005391264477066
                ]
            ],
            "accuracy": [
                0.4387755102040816,
                [
                    0.3469387755102041,
                    0.5408163265306123
                ]
            ],
            "precision": [
                0.7889093935446518,
                [
                    0.6884386735794747,
                    0.8434353238626667
                ]
            ],
            "recall": [
                0.5816326530612245,
                [
                    0.47959183673469385,
                    0.673469387755102
                ]
            ]
        }
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.4038982149997641,
                [
                    0.29548710555228774,
                    0.5096445883299118
                ]
            ],
            "accuracy": [
                0.30612244897959184,
                [
                    0.21428571428571427,
                    0.3979591836734694
                ]
            ],
            "precision": [
                0.7455835871881107,
                [
                    0.5908668313526034,
                    0.81545240425258
                ]
            ],
            "recall": [
                0.40816326530612246,
                [
                    0.3163265306122449,
                    0.5
                ]
            ]
        }
    },
    "biolinkbert": {
        "metrics": {
            "f1-weighted": [
                0.8102713612917694,
                [
                    0.7135937879971329,
                    0.886263657456856
                ]
            ],
            "accuracy": [
                0.826530612244898,
                [
                    0.7448979591836735,
                    0.8979591836734694
                ]
            ],
            "precision": [
                0.7963320463320464,
                [
                    0.6805562974448005,
                    0.8831966530743257
                ]
            ],
            "recall": [
                0.826530612244898,
                [
                    0.7448979591836735,
                    0.8979591836734694
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}