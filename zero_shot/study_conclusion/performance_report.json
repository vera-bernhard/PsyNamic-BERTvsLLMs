{
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.5498621070049641,
                [
                    0.44510834079133177,
                    0.6462168741573434
                ]
            ],
            "accuracy": [
                0.47959183673469385,
                [
                    0.37755102040816324,
                    0.5816326530612245
                ]
            ],
            "precision": [
                0.772028662581658,
                [
                    0.6658163265306123,
                    0.8334166384874361
                ]
            ],
            "recall": [
                0.5204081632653061,
                [
                    0.41836734693877553,
                    0.6122448979591837
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5978934945500295,
                [
                    0.4955853390895442,
                    0.6917170529967007
                ]
            ],
            "accuracy": [
                0.5204081632653061,
                [
                    0.41836734693877553,
                    0.6224489795918368
                ]
            ],
            "precision": [
                0.6871938775510203,
                [
                    0.5541443881956745,
                    0.7890213558113461
                ]
            ],
            "recall": [
                0.5510204081632653,
                [
                    0.4489795918367347,
                    0.6530612244897959
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 3
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.581275593889825,
                [
                    0.48084937757696905,
                    0.6777919054455778
                ]
            ],
            "accuracy": [
                0.5408163265306123,
                [
                    0.4387755102040816,
                    0.6428571428571429
                ]
            ],
            "precision": [
                0.6501874219075385,
                [
                    0.5161408687612993,
                    0.7553305758494395
                ]
            ],
            "recall": [
                0.5612244897959183,
                [
                    0.45918367346938777,
                    0.6632653061224489
                ]
            ]
        },
        "nr_faulty_parsable": 98,
        "nr_non_parsable": 0
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.035918367346938776,
                [
                    0.0,
                    0.10375382371988655
                ]
            ],
            "accuracy": [
                0.02040816326530612,
                [
                    0.0,
                    0.07142857142857142
                ]
            ],
            "precision": [
                0.14965986394557823,
                [
                    0.0,
                    0.2857142857142857
                ]
            ],
            "recall": [
                0.02040816326530612,
                [
                    0.0,
                    0.07142857142857142
                ]
            ]
        },
        "nr_faulty_parsable": 1,
        "nr_non_parsable": 95
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.7258268824771288,
                [
                    0.6299280046596621,
                    0.8084891648888267
                ]
            ],
            "accuracy": [
                0.7040816326530612,
                [
                    0.6122448979591837,
                    0.7857142857142857
                ]
            ],
            "precision": [
                0.7936174469787914,
                [
                    0.6791918193340145,
                    0.8657408771516117
                ]
            ],
            "recall": [
                0.7040816326530612,
                [
                    0.6122448979591836,
                    0.7857142857142857
                ]
            ]
        },
        "nr_faulty_parsable": 1,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.568903165065212,
                [
                    0.46869812012008527,
                    0.6615347136514974
                ]
            ],
            "accuracy": [
                0.3979591836734694,
                [
                    0.30612244897959184,
                    0.5
                ]
            ],
            "precision": [
                0.8106575963718821,
                [
                    0.7427489356956759,
                    0.8545281696143784
                ]
            ],
            "recall": [
                0.5204081632653061,
                [
                    0.42857142857142855,
                    0.6224489795918368
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 18
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.40404246547103695,
                [
                    0.29680619403593667,
                    0.5103340999369241
                ]
            ],
            "accuracy": [
                0.2857142857142857,
                [
                    0.20408163265306123,
                    0.37755102040816324
                ]
            ],
            "precision": [
                0.7487776888312425,
                [
                    0.596022343606461,
                    0.8196304192866235
                ]
            ],
            "recall": [
                0.3877551020408163,
                [
                    0.29591836734693877,
                    0.47959183673469385
                ]
            ]
        },
        "nr_faulty_parsable": 68,
        "nr_non_parsable": 8
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.20279397473275024,
                [
                    0.11589792301639022,
                    0.30882980228298285
                ]
            ],
            "accuracy": [
                0.23469387755102042,
                [
                    0.15306122448979592,
                    0.32653061224489793
                ]
            ],
            "precision": [
                0.8173469387755101,
                [
                    0.08984560105608536,
                    0.866980894174645
                ]
            ],
            "recall": [
                0.24489795918367346,
                [
                    0.16326530612244897,
                    0.336734693877551
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.14638660945916243,
                [
                    0.07746327623219298,
                    0.24142074157336413
                ]
            ],
            "accuracy": [
                0.21428571428571427,
                [
                    0.14285714285714285,
                    0.30612244897959184
                ]
            ],
            "precision": [
                0.4453479528457346,
                [
                    0.06521992803656643,
                    0.8543742556756143
                ]
            ],
            "recall": [
                0.21428571428571427,
                [
                    0.14285714285714285,
                    0.30612244897959184
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "biolinkbert": {
        "metrics": {
            "f1-weighted": [
                0.8102713612917694,
                [
                    0.7135937879971329,
                    0.886263657456856
                ]
            ],
            "accuracy": [
                0.826530612244898,
                [
                    0.7448979591836735,
                    0.8979591836734694
                ]
            ],
            "precision": [
                0.7963320463320464,
                [
                    0.6805562974448005,
                    0.8831966530743257
                ]
            ],
            "recall": [
                0.826530612244898,
                [
                    0.7448979591836735,
                    0.8979591836734694
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}