{
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.43073181263970745,
                [
                    0.32253349484280414,
                    0.5387583126757683
                ]
            ],
            "accuracy": [
                0.4375,
                [
                    0.34375,
                    0.5416666666666666
                ]
            ],
            "precision": [
                0.7990995762711864,
                [
                    0.5927290835923975,
                    0.864822010482685
                ]
            ],
            "recall": [
                0.4375,
                [
                    0.34375,
                    0.5416666666666666
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.2591030419016922,
                [
                    0.16369263959060584,
                    0.36697485186582113
                ]
            ],
            "accuracy": [
                0.2916666666666667,
                [
                    0.20833333333333334,
                    0.3854166666666667
                ]
            ],
            "precision": [
                0.8414439203354297,
                [
                    0.786712693388109,
                    0.8827726121694367
                ]
            ],
            "recall": [
                0.3333333333333333,
                [
                    0.23958333333333334,
                    0.4270833333333333
                ]
            ]
        },
        "nr_faulty_parsable": 17,
        "nr_non_parsable": 0
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.21638148608426155,
                [
                    0.13548539251429628,
                    0.3189937866036183
                ]
            ],
            "accuracy": [
                0.2916666666666667,
                [
                    0.20833333333333334,
                    0.3854166666666667
                ]
            ],
            "precision": [
                0.843844696969697,
                [
                    0.12310277419094856,
                    0.8909571246887923
                ]
            ],
            "recall": [
                0.3020833333333333,
                [
                    0.21875,
                    0.3958333333333333
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.12226641964545192,
                [
                    0.05657627017977324,
                    0.22181909108933012
                ]
            ],
            "accuracy": [
                0.13541666666666666,
                [
                    0.07291666666666667,
                    0.21875
                ]
            ],
            "precision": [
                0.6096230158730159,
                [
                    0.012732602744756925,
                    0.7684674564760419
                ]
            ],
            "recall": [
                0.14583333333333334,
                [
                    0.08333333333333333,
                    0.22916666666666666
                ]
            ]
        },
        "nr_faulty_parsable": 96,
        "nr_non_parsable": 0
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.37878461337513064,
                [
                    0.2740917037228379,
                    0.48529656657909764
                ]
            ],
            "accuracy": [
                0.3229166666666667,
                [
                    0.22916666666666666,
                    0.4166666666666667
                ]
            ],
            "precision": [
                0.8432539682539683,
                [
                    0.6721330359735795,
                    0.9062701813544567
                ]
            ],
            "recall": [
                0.3229166666666667,
                [
                    0.22916666666666666,
                    0.4166666666666667
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 7
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.4727725928192575,
                [
                    0.3606860947541346,
                    0.5780293545856395
                ]
            ],
            "accuracy": [
                0.46875,
                [
                    0.375,
                    0.5729166666666666
                ]
            ],
            "precision": [
                0.8561304644808744,
                [
                    0.8138452862330724,
                    0.8935363160523211
                ]
            ],
            "recall": [
                0.46875,
                [
                    0.375,
                    0.5729166666666666
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.05434782608695652,
                [
                    0.015625,
                    0.12162162162162164
                ]
            ],
            "accuracy": [
                0.041666666666666664,
                [
                    0.010416666666666666,
                    0.09375
                ]
            ],
            "precision": [
                0.078125,
                [
                    0.01875,
                    0.17857142857142858
                ]
            ],
            "recall": [
                0.041666666666666664,
                [
                    0.010416666666666666,
                    0.09375
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 88
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.6447887996941897,
                [
                    0.5407409410738785,
                    0.7351307287676621
                ]
            ],
            "accuracy": [
                0.59375,
                [
                    0.4895833333333333,
                    0.6875
                ]
            ],
            "precision": [
                0.7711755116172485,
                [
                    0.6393785752390378,
                    0.8568583116834272
                ]
            ],
            "recall": [
                0.59375,
                [
                    0.4895833333333333,
                    0.6875
                ]
            ]
        },
        "nr_faulty_parsable": 1,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.27875731346693233,
                [
                    0.18379662687133608,
                    0.3944598533793842
                ]
            ],
            "accuracy": [
                0.2708333333333333,
                [
                    0.1875,
                    0.3645833333333333
                ]
            ],
            "precision": [
                0.7763185215946843,
                [
                    0.38543296812795114,
                    0.8789295687331165
                ]
            ],
            "recall": [
                0.28125,
                [
                    0.19791666666666666,
                    0.375
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 33
    },
    "biobert": {
        "metrics": {
            "f1-weighted": [
                0.8918560606060607,
                [
                    0.8121390606633523,
                    0.9452365441742808
                ]
            ],
            "accuracy": [
                0.8958333333333334,
                [
                    0.8229166666666666,
                    0.9479166666666666
                ]
            ],
            "precision": [
                0.8934753316749586,
                [
                    0.790438299121028,
                    0.943418636561747
                ]
            ],
            "recall": [
                0.8958333333333334,
                [
                    0.8229166666666666,
                    0.9479166666666666
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}