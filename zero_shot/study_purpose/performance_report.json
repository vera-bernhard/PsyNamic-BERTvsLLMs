{
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5352319857341378,
                [
                    0.4687216541442296,
                    0.5996466068632551
                ]
            ],
            "accuracy": [
                0.18556701030927836,
                [
                    0.1134020618556701,
                    0.26804123711340205
                ]
            ],
            "precision": [
                0.6365629769885088,
                [
                    0.5640556184091332,
                    0.7648478245939002
                ]
            ],
            "recall": [
                0.5104895104895105,
                [
                    0.42699670304150517,
                    0.5902777777777778
                ]
            ]
        },
        "nr_faulty_parsable": 62,
        "nr_non_parsable": 11
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.735236528925246,
                [
                    0.658547864383475,
                    0.7968616882583698
                ]
            ],
            "accuracy": [
                0.4742268041237113,
                [
                    0.38144329896907214,
                    0.5773195876288659
                ]
            ],
            "precision": [
                0.7701727519541286,
                [
                    0.6886800777241255,
                    0.8271428570127899
                ]
            ],
            "recall": [
                0.7272727272727273,
                [
                    0.6503496503496503,
                    0.7941235094711162
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.7949953880900521,
                [
                    0.7298201291180217,
                    0.8462047508932172
                ]
            ],
            "accuracy": [
                0.5773195876288659,
                [
                    0.4742268041237113,
                    0.6701030927835051
                ]
            ],
            "precision": [
                0.8211046160048378,
                [
                    0.7480791992368387,
                    0.8692235715540019
                ]
            ],
            "recall": [
                0.7762237762237763,
                [
                    0.6963483945529885,
                    0.8384615384615385
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.7471162247027291,
                [
                    0.6763560493547789,
                    0.8037668672543047
                ]
            ],
            "accuracy": [
                0.4742268041237113,
                [
                    0.3711340206185567,
                    0.5670103092783505
                ]
            ],
            "precision": [
                0.7853917853917856,
                [
                    0.7033108581482264,
                    0.8389741824165299
                ]
            ],
            "recall": [
                0.7412587412587412,
                [
                    0.6689655172413793,
                    0.8057553956834532
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.5069062854189306,
                [
                    0.4314002031707132,
                    0.5848736076589448
                ]
            ],
            "accuracy": [
                0.2268041237113402,
                [
                    0.15463917525773196,
                    0.31958762886597936
                ]
            ],
            "precision": [
                0.48672165155418745,
                [
                    0.40670552515273733,
                    0.5628921008363044
                ]
            ],
            "recall": [
                0.5524475524475524,
                [
                    0.4676258992805755,
                    0.6356800370370224
                ]
            ]
        },
        "nr_faulty_parsable": 97,
        "nr_non_parsable": 0
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.8216599804405043,
                [
                    0.7740276325070502,
                    0.8614839591719109
                ]
            ],
            "accuracy": [
                0.5360824742268041,
                [
                    0.4329896907216495,
                    0.6391752577319587
                ]
            ],
            "precision": [
                0.7936374796213073,
                [
                    0.7300585957061158,
                    0.8396802949858363
                ]
            ],
            "recall": [
                0.8531468531468531,
                [
                    0.7919463087248322,
                    0.9037037037037037
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.7270721099043276,
                [
                    0.6710096436236626,
                    0.7750588975784335
                ]
            ],
            "accuracy": [
                0.35051546391752575,
                [
                    0.25773195876288657,
                    0.4536082474226804
                ]
            ],
            "precision": [
                0.6489203399017723,
                [
                    0.5893700054059848,
                    0.6979979696082351
                ]
            ],
            "recall": [
                0.8671328671328671,
                [
                    0.7959183673469388,
                    0.9178082191780822
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.7875655292551501,
                [
                    0.7369207543228551,
                    0.8288530015479524
                ]
            ],
            "accuracy": [
                0.4329896907216495,
                [
                    0.3402061855670103,
                    0.5360824742268041
                ]
            ],
            "precision": [
                0.7086197335293553,
                [
                    0.6493931979559837,
                    0.7557931232578639
                ]
            ],
            "recall": [
                0.8951048951048951,
                [
                    0.8394160583941606,
                    0.9375
                ]
            ]
        },
        "nr_faulty_parsable": 4,
        "nr_non_parsable": 1
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.040493507327049254,
                [
                    0.0,
                    0.142546518491709
                ]
            ],
            "accuracy": [
                0.020618556701030927,
                [
                    0.0,
                    0.07216494845360824
                ]
            ],
            "precision": [
                0.6643356643356644,
                [
                    0.29931972789115646,
                    0.7940802632613844
                ]
            ],
            "recall": [
                0.02097902097902098,
                [
                    0.0,
                    0.07922847237537059
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 95
    },
    "biobert": {
        "metrics": {
            "f1-weighted": [
                0.8126119991642607,
                [
                    0.7543618195335756,
                    0.860320930434186
                ]
            ],
            "accuracy": [
                0.5773195876288659,
                [
                    0.4742268041237113,
                    0.6701030927835051
                ]
            ],
            "precision": [
                0.8324807909874148,
                [
                    0.76735753334788,
                    0.8813450495067865
                ]
            ],
            "recall": [
                0.8041958041958042,
                [
                    0.7323943661971831,
                    0.8642857142857143
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}