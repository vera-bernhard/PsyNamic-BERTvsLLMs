{
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.735236528925246,
                [
                    0.658547864383475,
                    0.7968616882583698
                ]
            ],
            "accuracy": [
                0.4742268041237113,
                [
                    0.38144329896907214,
                    0.5773195876288659
                ]
            ],
            "precision": [
                0.7701727519541286,
                [
                    0.6886800777241255,
                    0.8271428570127899
                ]
            ],
            "recall": [
                0.7272727272727273,
                [
                    0.6503496503496503,
                    0.7941235094711162
                ]
            ]
        }
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.7222576956509356,
                [
                    0.6560007994211088,
                    0.778035450210394
                ]
            ],
            "accuracy": [
                0.4742268041237113,
                [
                    0.3711340206185567,
                    0.5670103092783505
                ]
            ],
            "precision": [
                0.8116463968303598,
                [
                    0.7351162091973124,
                    0.8650938821718601
                ]
            ],
            "recall": [
                0.6783216783216783,
                [
                    0.6,
                    0.7464788732394366
                ]
            ]
        }
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.7471162247027291,
                [
                    0.6763560493547789,
                    0.8037668672543047
                ]
            ],
            "accuracy": [
                0.4742268041237113,
                [
                    0.3711340206185567,
                    0.5670103092783505
                ]
            ],
            "precision": [
                0.7853917853917856,
                [
                    0.7033108581482264,
                    0.8389741824165299
                ]
            ],
            "recall": [
                0.7412587412587412,
                [
                    0.6689655172413793,
                    0.8057553956834532
                ]
            ]
        }
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.7811349445810555,
                [
                    0.7175479623148517,
                    0.8307812338883528
                ]
            ],
            "accuracy": [
                0.5360824742268041,
                [
                    0.4329896907216495,
                    0.6391752577319587
                ]
            ],
            "precision": [
                0.7742651055834037,
                [
                    0.7020757130775126,
                    0.8263646702494484
                ]
            ],
            "recall": [
                0.7972027972027972,
                [
                    0.7181208053691275,
                    0.8581560283687943
                ]
            ]
        }
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.5069062854189306,
                [
                    0.4314002031707132,
                    0.5848736076589448
                ]
            ],
            "accuracy": [
                0.2268041237113402,
                [
                    0.15463917525773196,
                    0.31958762886597936
                ]
            ],
            "precision": [
                0.48672165155418745,
                [
                    0.40670552515273733,
                    0.5628921008363044
                ]
            ],
            "recall": [
                0.5524475524475524,
                [
                    0.4676258992805755,
                    0.6356800370370224
                ]
            ]
        }
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.6300131241307713,
                [
                    0.5505790923990767,
                    0.7039286795563788
                ]
            ],
            "accuracy": [
                0.36082474226804123,
                [
                    0.26804123711340205,
                    0.4639175257731959
                ]
            ],
            "precision": [
                0.7256056636861591,
                [
                    0.6394165106793436,
                    0.793788326611278
                ]
            ],
            "recall": [
                0.5804195804195804,
                [
                    0.49264705882352944,
                    0.6622516556291391
                ]
            ]
        }
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.8216599804405043,
                [
                    0.7740276325070502,
                    0.8614839591719109
                ]
            ],
            "accuracy": [
                0.5360824742268041,
                [
                    0.4329896907216495,
                    0.6391752577319587
                ]
            ],
            "precision": [
                0.7936374796213073,
                [
                    0.7300585957061158,
                    0.8396802949858363
                ]
            ],
            "recall": [
                0.8531468531468531,
                [
                    0.7919463087248322,
                    0.9037037037037037
                ]
            ]
        }
    },
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.7875655292551501,
                [
                    0.7369207543228551,
                    0.8288530015479524
                ]
            ],
            "accuracy": [
                0.4329896907216495,
                [
                    0.3402061855670103,
                    0.5360824742268041
                ]
            ],
            "precision": [
                0.7086197335293553,
                [
                    0.6493931979559837,
                    0.7557931232578639
                ]
            ],
            "recall": [
                0.8951048951048951,
                [
                    0.8394160583941606,
                    0.9375
                ]
            ]
        }
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.7270721099043276,
                [
                    0.6710096436236626,
                    0.7750588975784335
                ]
            ],
            "accuracy": [
                0.35051546391752575,
                [
                    0.25773195876288657,
                    0.4536082474226804
                ]
            ],
            "precision": [
                0.6489203399017723,
                [
                    0.5893700054059848,
                    0.6979979696082351
                ]
            ],
            "recall": [
                0.8671328671328671,
                [
                    0.7959183673469388,
                    0.9178082191780822
                ]
            ]
        }
    },
    "tuned": {
        "metrics": {
            "f1-weighted": [
                0.7588998167607794,
                [
                    0.6914576244267957,
                    0.8167027956279218
                ]
            ],
            "accuracy": [
                0.5051546391752577,
                [
                    0.4020618556701031,
                    0.6082474226804123
                ]
            ],
            "precision": [
                0.8418037417026296,
                [
                    0.7668034344434729,
                    0.889763821748646
                ]
            ],
            "recall": [
                0.6993006993006993,
                [
                    0.6165413533834586,
                    0.7714285714285715
                ]
            ]
        }
    },
    "biobert": {
        "metrics": {
            "f1-weighted": [
                0.8126119991642607,
                [
                    0.7543618195335756,
                    0.860320930434186
                ]
            ],
            "accuracy": [
                0.5773195876288659,
                [
                    0.4742268041237113,
                    0.6701030927835051
                ]
            ],
            "precision": [
                0.8324807909874148,
                [
                    0.76735753334788,
                    0.8813450495067865
                ]
            ],
            "recall": [
                0.8041958041958042,
                [
                    0.7323943661971831,
                    0.8642857142857143
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "medgemma-27b-text-it": {
        "metrics": {
            "f1-weighted": [
                0.8089405543950999,
                [
                    0.7576358308112257,
                    0.8476539675353084
                ]
            ],
            "accuracy": [
                0.5051546391752577,
                [
                    0.41237113402061853,
                    0.5979381443298969
                ]
            ],
            "precision": [
                0.8094702399050225,
                [
                    0.7447719148089607,
                    0.8531707611543148
                ]
            ],
            "recall": [
                0.8111888111888111,
                [
                    0.7394243962273928,
                    0.8648648648648649
                ]
            ]
        }
    }
}