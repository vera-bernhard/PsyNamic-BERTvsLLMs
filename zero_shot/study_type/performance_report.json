{
    "gpt-4o-mini": {
        "metrics": {
            "f1-weighted": [
                0.4562604728622199,
                [
                    0.33709854789824306,
                    0.5661976805689666
                ]
            ],
            "accuracy": [
                0.44329896907216493,
                [
                    0.35051546391752575,
                    0.5463917525773195
                ]
            ],
            "precision": [
                0.7863393639242638,
                [
                    0.5800899463834838,
                    0.8237174261391482
                ]
            ],
            "recall": [
                0.5154639175257731,
                [
                    0.41237113402061853,
                    0.6185567010309279
                ]
            ]
        },
        "nr_faulty_parsable": 1,
        "nr_non_parsable": 0
    },
    "Llama-3.1-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.503897601578014,
                [
                    0.39214730789003,
                    0.6108551850021418
                ]
            ],
            "accuracy": [
                0.41237113402061853,
                [
                    0.31958762886597936,
                    0.5154639175257731
                ]
            ],
            "precision": [
                0.7912027491408935,
                [
                    0.37549810121573607,
                    0.8136946243817789
                ]
            ],
            "recall": [
                0.5773195876288659,
                [
                    0.4742268041237113,
                    0.6701030927835051
                ]
            ]
        },
        "nr_faulty_parsable": 6,
        "nr_non_parsable": 1
    },
    "MeLLaMA-70B-chat": {
        "metrics": {
            "f1-weighted": [
                0.15452202436738519,
                [
                    0.0894046520451691,
                    0.24838696772018237
                ]
            ],
            "accuracy": [
                0.08247422680412371,
                [
                    0.041237113402061855,
                    0.15463917525773196
                ]
            ],
            "precision": [
                0.3621993127147766,
                [
                    0.22509456933758465,
                    0.539614201930346
                ]
            ],
            "recall": [
                0.10309278350515463,
                [
                    0.05154639175257732,
                    0.17525773195876287
                ]
            ]
        },
        "nr_faulty_parsable": 16,
        "nr_non_parsable": 80
    },
    "MeLLaMA-13B-chat": {
        "metrics": {
            "f1-weighted": [
                0.5650237758333574,
                [
                    0.4591772918909471,
                    0.6624272871193759
                ]
            ],
            "accuracy": [
                0.4948453608247423,
                [
                    0.3917525773195876,
                    0.5979381443298969
                ]
            ],
            "precision": [
                0.6539932304989278,
                [
                    0.5036399094948457,
                    0.7581307978783692
                ]
            ],
            "recall": [
                0.5360824742268041,
                [
                    0.4329896907216495,
                    0.6391752577319587
                ]
            ]
        },
        "nr_faulty_parsable": 7,
        "nr_non_parsable": 17
    },
    "gpt-4o-2024-08-06": {
        "metrics": {
            "f1-weighted": [
                0.6216621967076789,
                [
                    0.5104601842619205,
                    0.7243185550540193
                ]
            ],
            "accuracy": [
                0.6391752577319587,
                [
                    0.5463917525773195,
                    0.7319587628865979
                ]
            ],
            "precision": [
                0.7892291665790384,
                [
                    0.6021856629523412,
                    0.8355817290355593
                ]
            ],
            "recall": [
                0.6391752577319587,
                [
                    0.5463917525773195,
                    0.7319587628865979
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Meta-Llama-3-8B-Instruct": {
        "metrics": {
            "f1-weighted": [
                0.6015008305678887,
                [
                    0.48749721855827,
                    0.695034368938229
                ]
            ],
            "accuracy": [
                0.5463917525773195,
                [
                    0.44329896907216493,
                    0.6494845360824743
                ]
            ],
            "precision": [
                0.7743292082891842,
                [
                    0.6040697586690642,
                    0.8176720012841387
                ]
            ],
            "recall": [
                0.6391752577319587,
                [
                    0.5360824742268041,
                    0.7319587628865979
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-70b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.6585776543185725,
                [
                    0.5539774228547933,
                    0.7441509451505366
                ]
            ],
            "accuracy": [
                0.6082474226804123,
                [
                    0.5051546391752577,
                    0.7010309278350515
                ]
            ],
            "precision": [
                0.7630763484237263,
                [
                    0.6269909153210255,
                    0.8161911438839076
                ]
            ],
            "recall": [
                0.6804123711340206,
                [
                    0.5773195876288659,
                    0.7731958762886598
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Llama-2-13b-chat-hf": {
        "metrics": {
            "f1-weighted": [
                0.5410718963252413,
                [
                    0.4320619499738158,
                    0.6482862993822325
                ]
            ],
            "accuracy": [
                0.5670103092783505,
                [
                    0.4639175257731959,
                    0.6597938144329897
                ]
            ],
            "precision": [
                0.6545642456657107,
                [
                    0.5060402164640609,
                    0.78705653173824
                ]
            ],
            "recall": [
                0.5773195876288659,
                [
                    0.4742268041237113,
                    0.6701030927835051
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    },
    "Med-LLaMA3-8B": {
        "metrics": {
            "f1-weighted": [
                0.3050233804588586,
                [
                    0.21912530281764303,
                    0.40765589049285605
                ]
            ],
            "accuracy": [
                0.30927835051546393,
                [
                    0.2268041237113402,
                    0.40520884549130776
                ]
            ],
            "precision": [
                0.4192439862542956,
                [
                    0.2752466065942668,
                    0.6055322154870442
                ]
            ],
            "recall": [
                0.3402061855670103,
                [
                    0.24742268041237114,
                    0.44329896907216493
                ]
            ]
        },
        "nr_faulty_parsable": 95,
        "nr_non_parsable": 2
    },
    "clinicalbert": {
        "metrics": {
            "f1-weighted": [
                0.8707412862052037,
                [
                    0.7905528292710534,
                    0.9268839166356126
                ]
            ],
            "accuracy": [
                0.865979381443299,
                [
                    0.7835051546391752,
                    0.9175257731958762
                ]
            ],
            "precision": [
                0.8789345720766607,
                [
                    0.7900749563969184,
                    0.9316097340295442
                ]
            ],
            "recall": [
                0.865979381443299,
                [
                    0.7835051546391752,
                    0.9175257731958762
                ]
            ]
        },
        "nr_faulty_parsable": 0,
        "nr_non_parsable": 0
    }
}